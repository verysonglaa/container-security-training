[{"body":"The command line tool First it is time to become familiar with the command line utility. Using Docker consists of passing at least one command. docker --help shows the available options:\ndocker --help Usage: docker COMMAND A self-sufficient runtime for containers Options: --config string Location of client config files (default \"/home/user/.docker\") -D, --debug Enable debug mode --help Print usage -H, --host list Daemon socket(s) to connect to -l, --log-level string Set the logging level (\"debug\"|\"info\"|\"warn\"|\"error\"|\"fatal\") (default \"info\") --tls Use TLS; implied by --tlsverify --tlscacert string Trust certs signed only by this CA (default \"/home/user/.docker/ca.pem\") --tlscert string Path to TLS certificate file (default \"/home/user/.docker/cert.pem\") --tlskey string Path to TLS key file (default \"/home/user/.docker/key.pem\") --tlsverify Use TLS and verify the remote -v, --version Print version information and quit Management Commands: config Manage Docker configs container Manage containers image Manage images network Manage networks node Manage Swarm nodes plugin Manage plugins secret Manage Docker secrets service Manage services stack Manage Docker stacks swarm Manage Swarm system Manage Docker volume Manage volumes Commands: attach Attach local standard input, output, and error streams to a running container build Build an image from a Dockerfile commit Create a new image from a container's changes cp Copy files/folders between a container and the local filesystem create Create a new container diff Inspect changes to files or directories on a container's filesystem events Get real time events from the server exec Run a command in a running container export Export a container's filesystem as a tar archive history Show the history of an image images List images import Import the contents from a tarball to create a filesystem image info Display system-wide information inspect Return low-level information on Docker objects kill Kill one or more running containers load Load an image from a tar archive or STDIN login Log in to a Docker registry logout Log out from a Docker registry logs Fetch the logs of a container pause Pause all processes within one or more containers port List port mappings or a specific mapping for the container ps List containers pull Pull an image or a repository from a registry push Push an image or a repository to a registry rename Rename a container restart Restart one or more containers rm Remove one or more containers rmi Remove one or more images run Run a command in a new container save Save one or more images to a tar archive (streamed to STDOUT by default) search Search the Docker Hub for images start Start one or more stopped containers stats Display a live stream of container(s) resource usage statistics stop Stop one or more running containers tag Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE top Display the running processes of a container unpause Unpause all processes within one or more containers update Update configuration of one or more containers version Show the Docker version information wait Block until one or more containers stop, then print their exit codes Run 'docker COMMAND --help' for more information on a command. To view the switches available to a specific command, type:\ndocker \u003ccommand\u003e --help To view system-wide information about Docker, use:\ndocker info Hello world (with Docker images) Docker containers are run from Docker images. By default, they pull these images from Docker Hub, a Docker registry managed by Docker Inc, the company behind the Docker project. Anybody can build and host their Docker images on Docker Hub, so for many applications and Linux distributions you‚Äôll find Docker images that are hosted on Docker Hub.\nTo check whether you can access and download images from Docker Hub, type:\ndocker run hello-world The output, which should include the following, indicates that Docker appears to be working correctly:\nHello from Docker. This message shows that your installation appears to be working correctly. ... Your first container üòÉ With this command, we just ran our first container on our computers. It ran a simple process that printed a message to standard out, the container itself is not very useful though.\n","categories":"","description":"","excerpt":"The command line tool First it is time to become familiar with the ‚Ä¶","ref":"/docs/container-basics/01-basics/","tags":"","title":"Docker Basics"},{"body":"Docker images You can search for images available on Docker Hub by clicking the Explore link or by typing mariadb into the search field: https://hub.docker.com/search/?q=mariadb\u0026type=image You will get a list of results and the first hit will probably be the official image: https://hub.docker.com/_/mariadb This page contains instructions on how to pull the image. Let‚Äôs pull a certain version of mariadb:\ndocker pull mariadb:11.5 Note Care about security! Check the images before you run them. Is it an official image ? Official Images are a good starting point, please read here why.\nWhat is installed in the image?\nRead the Dockerfile that was used to build the image Check the base image Check the vulnerabilitis of this image. Does it affect your application? Check the dependencies of the image. Compare your images Digest to the sha256 value shown on dockerhub. After an image has been downloaded, you may then run a container using the downloaded image with the sub-command run. If an image has not been downloaded when Docker is executed with the sub-command run, the Docker client will first download the image, then run a container using it:\ndocker run hello-world:linux Note Here we use the linux tag of the hello-world image instead of using latest again. To see the images that have been downloaded to your computer type:\ndocker images The output should look similar to the following:\nREPOSITORY TAG IMAGE ID CREATED SIZE mariadb 11.5 58730544b81b 2 weeks ago 397MB hello-world latest 1815c82652c0 2 months ago 1.84kB The hello world container you ran in the previous lab is an example of a container that runs and exits, after emitting a test message. Containers, however, can be much more useful than that, and they can be interactive. After all, they are similar to virtual machines, only more resource-friendly.\nAs an example, let‚Äôs run a container using the downloaded image of MariaDB. The combination of the -i and -t switches gives you interactive shell access to the container:\ndocker run -it mariadb:11.5 An error has popped up!\n2022-08-09 08:19:21+00:00 [Note] [Entrypoint]: Entrypoint script for MariaDB Server 1:10.8.3+maria~jammy started. 2022-08-09 08:19:21+00:00 [Note] [Entrypoint]: Switching to dedicated user 'mysql' 2022-08-09 08:19:21+00:00 [Note] [Entrypoint]: Entrypoint script for MariaDB Server 1:10.8.3+maria~jammy started. 2022-08-09 08:19:21+00:00 [ERROR] [Entrypoint]: Database is uninitialized and password option is not specified You need to specify one of MARIADB_ROOT_PASSWORD, MARIADB_ALLOW_EMPTY_ROOT_PASSWORD and MARIADB_RANDOM_ROOT_PASSWORD ü§î Why do I get an error? Is this a bug in the image? Everything is fine, to run this image there is some configuration needed. Read the following excerpt carefully.\nerror: database is uninitialized and password option is not specified You need to specify one of MARIADB_ROOT_PASSWORD, MARIADB_ALLOW_EMPTY_ROOT_PASSWORD and MARIADB_RANDOM_ROOT_PASSWORD We will add the configuration later.\nü§î What's an image? Think of an image like a blueprint of what will be in a container when it runs.\nAn image is a collection of files + some metadata (or in technical terms: those files form the root filesystem of a container) Images are made of layers, conceptually stacked on top of each other Each layer can add, change or remove files Images can share layers to optimize disk usage, transfer times and memory use You build these images using Dockerfiles (in later labs) Images are immutable, you cannot change them after creation ü§î What's the difference between a container and an image? When you run an image, it becomes a container.\nAn image is a read-only filesystem A container is an encapsulated set of processes running in a read-write copy of that filesystem To optimize container boot time, copy-on-write is used instead of regular copy docker run starts a container from a given image ","categories":"","description":"","excerpt":"Docker images You can search for images available on Docker Hub by ‚Ä¶","ref":"/docs/container-basics/01-basics/01/_images/","tags":"","title":"Images"},{"body":"Docker architecture Docker is a client-server application The Docker daemon (or ‚ÄúEngine‚Äù) Receives and processes incoming Docker API requests The Docker client Talks to the Docker daemon via the Docker API We‚Äôll use mostly the CLI embedded within the Docker binary The Docker Hub Registry Is a collection of public images The Docker daemon talks to it via the registry API The Docker installation will install the Docker daemon and client on your workstation.\nSetup introduction This training depends on an installation of Docker. If you are attending an official training you are given a pre-installed environment, you can skip this step.\nIf not, follow the instructions on the subsequent pages to complete the setup on your platform of choice.\n","categories":"","description":"","excerpt":"Docker architecture Docker is a client-server application The Docker ‚Ä¶","ref":"/setup/","tags":"","title":"Setup"},{"body":"Environment variables So why was there an error in the previous lab? The MariaDB server is not able to run without a proper configuration. Docker can pass variables into the instantiation process via environment variables. Environment variables are passed via the parameter -e, e.g.:\ndocker run -it -e MARIADB_ROOT_PASSWORD=my-secret-pw mariadb Once you run the command you will see an output like this:\nInitializing database PLEASE REMEMBER TO SET A PASSWORD FOR THE MariaDB root USER ! To do so, start the server, then issue the following commands: '/usr/bin/mysqladmin' -u root password 'new-password' '/usr/bin/mysqladmin' -u root -h password 'new-password' Alternatively you can run: '/usr/bin/mysql_secure_installation' which will also give you the option of removing the test databases and anonymous user created by default. This is strongly recommended for production servers. See the MariaDB Knowledgebase at http://mariadb.com/kb or the MySQL manual for more instructions. Please report any problems at http://mariadb.org/jira The latest information about MariaDB is available at http://mariadb.org/. You can find additional information about the MySQL part at: http://dev.mysql.com Consider joining MariaDB's strong and vibrant community: https://mariadb.org/get-involved/ Database initialized MySQL init process in progress... 2020-05-27 6:21:03 0 [Note] mysqld (mysqld 10.3.7-MariaDB-1:10.3.7+maria~jessie) starting as process 101 ... 2020-05-27 6:21:03 0 [Note] InnoDB: Using Linux native AIO 2020-05-27 6:21:03 0 [Note] InnoDB: Mutexes and rw_locks use GCC atomic builtins 2020-05-27 6:21:03 0 [Note] InnoDB: Uses event mutexes 2020-05-27 6:21:03 0 [Note] InnoDB: Compressed tables use zlib 1.2.8 2020-05-27 6:21:03 0 [Note] InnoDB: Number of pools: 1 2020-05-27 6:21:03 0 [Note] InnoDB: Using SSE2 crc32 instructions 2020-05-27 6:21:03 0 [Note] InnoDB: Initializing buffer pool, total size = 256M, instances = 1, chunk size = 128M ... 2020-05-27 6:21:08 0 [Note] mysqld: ready for connections. Version: '10.3.7-MariaDB-1:10.3.7+maria~jessie' socket: '/var/run/mysqld/mysqld.sock' port: 3306 mariadb.org binary distribution If you re-read the command above you will notify that we used the arguments -it (interactive/terminal). And you might have also found out that mariadb does not react to the usual CTRL-c. So how do we exit this terminal? Docker has an escape sequence to detach from a container and leave it running. For this you have to press CTRL-p and then CTRL-q in bash. In the webshell the shortcuts CTRL-p and CTRL-q are not working. Simply close the terminal and open a new one as a workaround.\nThis will leave the container running while you are back in your shell. To verify that the container is running use the following command:\ndocker ps The output should look much like this:\nCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 7cb31f821233 mariadb \"docker-entrypoint...\" 5 minutes ago Up 5 minutes 3306/tcp upbeat_blackwell Access the container To connect to the container again you can use the following command:\ndocker exec -it \u003ccontainer\u003e bash Where \u003ccontainer\u003e can refer to the CONTAINER ID (the first two characters are normally sufficient) or one of the NAMES from the output of docker ps. In the above output this would be 7cb31f821233 or upbeat_blackwell but in your case this is a different name and ID.\nNote The docker exec command needs either the ID or NAME of the container. Additionally, at the end, an executable. In this example, it‚Äôs bash as we want to do something interactively in the container.\nOnce the command is executed you should see this:\nroot@7cb31f821233:/#\nNote Every time you connect yourself to a container you will always be the user that was defined in the Dockerfile. Now that we are connected, let‚Äôs find out if the MariaDB is working‚Ä¶\nmariadb -uroot -pmy-secret-pw If everything works as expected, you should now see the MariaDB command line:\nWelcome to the MariaDB monitor. Commands end with ; or \\g. Your MariaDB connection id is 8 Server version: 10.3.8-MariaDB-1:10.3.8+maria~jessie mariadb.org binary distribution Copyright (c) 2000, 2020, Oracle, MariaDB Corporation Ab and others. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. MariaDB [(none)]\u003e Type\nexit; to leave the mysql client. Type\nexit one more time to leave the container.\nDetached containers One might think: This whole starting process is a bit cumbersome with CTRL-p and then CTRL-q. Therefore, you can run a Docker container directly with -d (detached) mode, e.g.:\ndocker run -it -e MARIADB_ROOT_PASSWORD=my-secret-pw -d mariadb Instead of the output of the container itself, you will now only get the ID of the started container. If you have a look into the container list, you should see two running containers:\ndocker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 699e82ed8f1f mariadb \"docker-entrypoint...\" 3 minutes ago Up 3 minutes 3306/tcp jolly_bardeen 7cb31f821233 mariadb \"docker-entrypoint...\" 32 minutes ago Up 32 minutes 3306/tcp upbeat_blackwell We don‚Äôt need both of them running. To stop a container use the command:\ndocker stop \u003ccontainer\u003e After that, check the new state with\ndocker ps This should show only one container running:\nCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 699e82ed8f1f mariadb \"docker-entrypoint...\" 9 minutes ago Up 9 minutes 3306/tcp jolly_bardeen We just exited the container ‚Äúgracefully‚Äù, but as an alternative you can also kill a container with the docker kill \u003ccontainer\u003e command. This stops the container immediately by using the KILL signal.\nYou may recognize that the container upbeat_blackwell is not present in the container list anymore. That is because docker ps only shows running containers, but as always you have a parameter that helps:\ndocker ps --all CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 699e82ed8f1f mariadb \"docker-entrypoint...\" 12 minutes ago Up 12 minutes 3306/tcp jolly_bardeen 7cb31f821233 mariadb \"docker-entrypoint...\" 41 minutes ago Exited (0) 2 minutes ago upbeat_blackwell 67d79f95c712 hello-world \"/hello\" About an hour ago Exited (0) About an hour ago upbeat_boyd Now that the upbeat_blackwell container is stopped delete it:\ndocker rm \u003ccontainer\u003e Now the container has disappeared from the list:\ndocker ps --all CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 699e82ed8f1f mariadb \"docker-entrypoint...\" 13 minutes ago Up 13 minutes 3306/tcp jolly_bardeen 67d79f95c712 hello-world \"/hello\" About an hour ago Exited (0) About an hour ago upbeat_boyd It is a good idea to delete unused containers to save disk space and remove the data wich resides in the read/write layer of the container. So please delete the hello-word container too:\ndocker rm \u003ccontainer\u003e Mounting a volume in a container ü§î I have a container with a database server running. What happens to my data when I remove the container? It‚Äôs gone. The docker instance has no persistence layer to store data permanently, let us address that problem in this chapter.\nThe MariaDB container is a good example as to why it‚Äôs good to have an external volume. There are several possibilities on how to work with volumes in Docker, in this case, we‚Äôre going to create a docker volume to store the persistent data of our MariaDB. The volume is managed by Docker itself.\nCreate the docker-managed volume and attach it to a path in the container:\ndocker volume create volume-mariadb docker run --name mariadb-container-with-external-volume -v volume-mariadb:/var/lib/mysql -e MARIADB_ROOT_PASSWORD=my-secret-pw -d mariadb In case you are wondering where your data ends up you can inspect the volume with:\ndocker volume inspect volume-mariadb Okay, now create a new user in the MariaDB container:\ndocker exec -it mariadb-container-with-external-volume mariadb -uroot -pmy-secret-pw Inside the mariadb-client execute some SQL commands to grant user peter read permissions to the user table:\nuse mysql CREATE USER 'peter'@'%' IDENTIFIED BY 'venkman'; GRANT SELECT ON mysql.user TO 'peter'@'%'; Once all steps are completed quit the mysql session which also will exit the container:\nexit We have added a new user to our DB and persistet the data through the use of volumes!\n","categories":"","description":"","excerpt":"Environment variables So why was there an error in the previous lab? ‚Ä¶","ref":"/docs/container-basics/01-basics/01/_env-vars/","tags":"","title":"Environment variables"},{"body":"\nContainer Basics and Security","categories":"","description":"","excerpt":"\nContainer Basics and Security","ref":"/docs/","tags":"","title":"Labs"},{"body":"Frontend Let us create a frontend to showcase port-forwarding and the connection between containers. We will run a simple python webserver which display all the users in our mariadb.\nFirst get the IP of the currently running mariadb container. By default all container are started in the bridge network, where no DNS service is available and we can‚Äôt use container name. As a workaround we use the IP of the container:\nexport ip=$(docker inspect mariadb-container-with-external-volume -f '{{ range.NetworkSettings.Networks }}{{ .IPAddress }}{{ end }}') docker inspect \u003ccontainer\u003e shows you details about a running container in JSON format (run it yourself and take a look at it). We filtered the json to only get the IP address of the container.\nWe could also have filtered the output with grep: docker inspect mariadb-container | grep IPAddress but our solution is more elegant üòä.\nNext we start the frontend container, lucky for us there is an image available online. If interested you can check the source-code here :\ndocker run -d --name frontend -e username=peter -e password=venkman -e servername=$ip grafgabriel/container-lab-frontend Now how do we access it? Try to connect to the server using the container-assigned docker IP address:\ndocker inspect frontend -f '{{ range.NetworkSettings.Networks }}{{ .IPAddress }}{{ end }}' Which will show only the IP of the container as output:\n172.17.0.4 As we don‚Äôt have a browser in the webshell use curl http://172.17.0.4:5000 to open the page in your terminal. On alocal installation you could simply open http://172.17.0.4:5000 using your browser.\ncurl http://172.17.0.4:5000` ","categories":"","description":"","excerpt":"Frontend Let us create a frontend to showcase port-forwarding and the ‚Ä¶","ref":"/docs/container-basics/01-basics/01/_frontend/","tags":"","title":"Frontend"},{"body":"Installation for Windows Please follow the instructions on Docker‚Äôs official documentation to install Docker CE for Windows.\nWhen asked to use Windows container, choose NOT to.\nNote You don‚Äôt have to register for a Docker Cloud account. Shell recommendation for Windows We highly recommend to use the Bash emulation Git Bash from Git for Windows to do the exercises in this training.\nProxy configuration for Windows If your organization has a proxy in place you have to set the proxy environment variables in order to be able to do docker pull or docker push.\nGit Bash:\nexport HTTP_PROXY=\"http://\u003cusername\u003e:\u003cpassword\u003e@\u003cproxy\u003e:\u003cport\u003e\" export HTTPS_PROXY=\"http://\u003cusername\u003e:\u003cpassword\u003e@\u003cproxy\u003e:\u003cport\u003e\" Note If you have special characters in your password, you have to encode them according to Percent-encoding reserved characters . See also setting the proxy environment variables on Windows for alternative instructions on setting proxy environment variables.\nNext steps When you‚Äôre ready to go, head on over to the labs and begin with the training!\n","categories":"","description":"","excerpt":"Installation for Windows Please follow the instructions on Docker‚Äôs ‚Ä¶","ref":"/setup/01/","tags":"","title":"Installation for Windows"},{"body":" Please download the slides from moodle Read more\n","categories":"","description":"","excerpt":" Please download the slides from moodle Read more\n","ref":"/slides/","tags":"","title":"Slides"},{"body":"Dockerfile Docker can build container images by reading the instructions on how to build the image from a so-called Dockerfile or more generally, Containerfile. The basic docs on how Dockerfiles work can be found at https://docs.docker.com/engine/reference/builder/ .\nWrite your first Dockerfile Let us have a general look at how to build a container image. For that, create a new directory with an empty Dockerfile in there.\nmkdir myfirstimage cd myfirstimage Create a new File with the name Dockerfile and add the following content to that Dockerfile using your editor of choice:\nFROM ubuntu RUN apt-get update \u0026\u0026 \\ apt-get install -y figlet \u0026\u0026 \\ apt-get clean FROM indicates the base image for our build Each RUN line will be executed by Docker during the build Our RUN commands must be non-interactive (no input can be provided to Docker during the build) Check https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/ for further best practices on how to write Dockerfiles. Build the image Just run:\ndocker build -t myfirstimage . -t indicates the tag to apply to the image . indicates the location of the build context (which we will talk more about later, but is basically the directory where our Dockerfile is located) Please note that the tag can be omitted in most Docker commands and instructions. In that case, the tag defaults to latest. Besides being the default tag there‚Äôs nothing special about latest. Despite its name, it does not necessarily identify the latest version of an image.\nDepending on the build system it can point to the last image pushed, to the last image built from some branch, or to some old image. It can even not exist at all.\nBecause of this, you must never use the latest tag in production, always use a specific image version.\nAlso see: https://medium.com/@mccode/the-misunderstood-docker-tag-latest-af3babfd6375 What happens when we build the image The output of the Docker build looks similiar to this:\n[+] Building 13.3s (6/6) FINISHED docker:default =\u003e [internal] load build definition from Dockerfile 0.1s =\u003e =\u003e transferring dockerfile: 127B 0.0s =\u003e [internal] load metadata for docker.io/library/ubuntu:latest 1.4s =\u003e [internal] load .dockerignore 0.1s =\u003e =\u003e transferring context: 2B 0.0s =\u003e [1/2] FROM docker.io/library/ubuntu:latest@sha256:99c35190e22d294cdace2783ac55effc69d32896daaa265f0bbedbcde4fbe3e5 3.1s =\u003e =\u003e resolve docker.io/library/ubuntu:latest@sha256:99c35190e22d294cdace2783ac55effc69d32896daaa265f0bbedbcde4fbe3e5 0.1s =\u003e =\u003e sha256:99c35190e22d294cdace2783ac55effc69d32896daaa265f0bbedbcde4fbe3e5 6.69kB / 6.69kB 0.0s =\u003e =\u003e sha256:5d070ad5f7fe63623cbb99b4fc0fd997f5591303d4b03ccce50f403957d0ddc4 424B / 424B 0.0s =\u003e =\u003e sha256:59ab366372d56772eb54e426183435e6b0642152cb449ec7ab52473af8ca6e3f 2.30kB / 2.30kB 0.0s =\u003e =\u003e sha256:ff65ddf9395be21bfe1f320b7705e539ee44c1053034f801b1a3cbbf2d0f4056 29.75MB / 29.75MB 0.9s =\u003e =\u003e extracting sha256:ff65ddf9395be21bfe1f320b7705e539ee44c1053034f801b1a3cbbf2d0f4056 1.7s =\u003e [2/2] RUN apt-get update \u0026\u0026 apt-get install -y figlet \u0026\u0026 apt-get clean 8.1s =\u003e exporting to image 0.3s =\u003e =\u003e exporting layers 0.2s =\u003e =\u003e writing image sha256:9739703b2866e9100738cefc2f5c7cb0b9cd2b005e5770829a7608ca55bdcfb5 0.0s =\u003e =\u003e naming to docker.io/library/myfirstimage Sending the build context to Docker transferring context: 2B ... The build context is the . directory given to docker build It is sent (as an archive) to the Docker daemon by the Docker client This allows you to use a remote machine to build using local files Be careful (or patient) if that directory is big and your connection is slow Inspecting step execution ... [1/2] FROM docker.io/library/ubuntu:latest =\u003e =\u003e resolve docker.io/library/ubuntu:latest =\u003e =\u003e sha256:99c35190e22d294cdace2783ac55effc69d32896daaa265f0bbedbcde4fbe3e5 6.69kB / 6.69kB [...] =\u003e =\u003e extracting sha256:ff65ddf9395be21bfe1f320b7705e539ee44c1053034f801b1a3cbbf2d0f4056 [2/2] RUN apt-get update \u0026\u0026 apt-get install -y figlet \u0026\u0026 apt-get clean 8.1s =\u003e exporting to image 0.3s =\u003e =\u003e exporting layers 0.2s =\u003e =\u003e writing image sha256:9739703b2866e9100738cefc2f5c7cb0b9cd2b005e5770829a7608ca55bdcfb5 0.0s =\u003e =\u003e naming to docker.io/library/myfirstimage This output shows the stages involved in building an image from a Dockerfile. Here‚Äôs a breakdown of each step:\n[internal] load build definition from Dockerfile (0.1s): Docker reads the Dockerfile and loads its contents.\n[internal] load metadata for docker.io/library/ubuntu:latest (1.4s): Docker fetches metadata for the ubuntu:latest image from Docker Hub to check if it‚Äôs up-to-date.\n[internal] load .dockerignore (0.1s): Docker loads .dockerignore to exclude specific files from the build context.\n[1/2] FROM docker.io/library/ubuntu:latest (3.1s): Docker starts downloading the ubuntu:latest image with a specific hash sha256:99c35190....\nsha256 entries represent different image layers: For example, ff65ddf... is a 29.75 MB layer, which Docker downloads and extracts. [2/2] RUN apt-get update \u0026\u0026 apt-get install -y figlet \u0026\u0026 apt-get clean (8.1s): Docker executes the RUN command to:\nUpdate the package list (apt-get update), Install the figlet package, and Clean up cached package files (apt-get clean) to reduce image size. exporting to image (0.3s): Docker finalizes the build by:\nExporting the layers, Writing the image with identifier sha256:9739703..., and Naming the image myfirstimage in the Docker library. Total Build Time:\nThe entire build process took 13.3 seconds, with most time spent downloading layers and installing packages.\nThe caching system If you run the same build again, it will be instantaneous. Why?\nAfter each build step, Docker takes a snapshot Before executing a step, Docker checks if it has already built the same sequence Docker uses the exact strings defined in your Dockerfile: RUN apt-get install figlet cowsay is different from RUN apt-get install cowsay figlet RUN apt-get update is not re-executed when the mirrors are updated All steps after a modified step are re-executed since the filesystem it‚Äôs based on may have changed You can force a rebuild with docker build ‚Äìno-cache ‚Ä¶\nRun it Now run your image\ndocker run -ti myfirstimage You‚Äôll find yourself inside a Bash shell in the container, execute\nfiglet hello and you will see the following output:\nroot@00f0766080ed:/# figlet hello _ _ _ | |__ ___| | | ___ | '_ \\ / _ \\ | |/ _ \\ | | | | __/ | | (_) | |_| |_|\\___|_|_|\\___/ root@00f0766080ed:/# exit the container by executing:\nexit The CMD instruction in Dockerfile With the CMD instruction in the Dockerfile, we can define the command that is executed when a container is started.\nü§î Can you find out which CMD instruction the ubuntu image has? You did find yourself in a shell, so the instruction must either be /usr/bin/bash or /usr/bin/sh.\nModify the previously created Dockerfile as follows:\nFROM ubuntu RUN apt-get update \u0026\u0026 \\ apt-get install -y figlet \u0026\u0026 \\ apt-get clean CMD [\"figlet\", \"hello\"] Build the image with:\ndocker build -t myfirstimagecmd . And run it:\ndocker run -ti myfirstimagecmd It directly executes the defined command and prints out\n_ _ _ | |__ ___| | | ___ | '_ \\ / _ \\ | |/ _ \\ | | | | __/ | | (_) | |_| |_|\\___|_|_|\\___/ Check out https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact for more information.\nFrontend app image build Now we are familiar with the image building process we have a more detailed look at our frontend image. You can find the source code here .\nWe see that the developer has become quite lazy and has not updated the python to the latest version, he did not even care to create sensible tags. So let us do it ourselves using the tag v1.0\nCheck out the repository\ncd /home/project git clone https://github.com/songlaa/container-lab-fronted cd container-lab-fronted You should have the necessary knowledge now to update and rebuild the image locally. Delete the currently running container and start a new one with updated python.\nüò≥ I'm lost, show me the solution First of all we need to check for the latest python base image. You could do this in dockerhub:\ngrep FROM Dockerfile We see that currently we use version 3.9 of python, a look at https://hub.docker.com/_/python shows us that that the most recent version, at the time of writing is 3.12.\nReplace the from line with this new value\nFROM python:3.12-slim And then we build it using tag v1.0\ndocker build -t container-lab-frontend:v1.0 . docker images Finally we kill the currently running container and start our new one, hopefully we still have $ip saved in our shell:\ndocker stop frontend docker rm frontend docker run -d --name frontend -e username=peter -e password=venkman -e servername=$ip container-lab-frontend:v1.0 ü§î What did we update by rebuilding the image? We did not only update python to a recent version but also the modules in python! Generally you should build \u0026 deploy very often to avoid configuration drift and keep your software up to date! A common solution to update your dependencies is https://docs.renovatebot.com/ ","categories":"","description":"","excerpt":"Dockerfile Docker can build container images by reading the ‚Ä¶","ref":"/docs/container-basics/01-basics/01/_dockerfile/","tags":"","title":"Dockerfile"},{"body":"Installation for Mac Please follow the instructions on Docker‚Äôs official documentation to install Docker CE for Mac.\nNote You don‚Äôt have to register for a Docker Cloud account. Proxy configuration for Mac If your organization has a proxy in place you have to set the proxy environment variables in order to be able to do docker pull or docker push.\nexport http_proxy=\"http://\u003cusername\u003e:\u003cpassword\u003e@\u003cproxy\u003e:\u003cport\u003e\" export https_proxy=\"http://\u003cusername\u003e:\u003cpassword\u003e@\u003cproxy\u003e:\u003cport\u003e\" Note If you have special characters in your password, you have to encode them according to Percent-encoding reserved characters . See also setting the proxy environment variables on Mac for alternative instructions on setting proxy environment variables.\nNext steps When you‚Äôre ready to go, head on over to the labs and begin with the training!\n","categories":"","description":"","excerpt":"Installation for Mac Please follow the instructions on Docker‚Äôs ‚Ä¶","ref":"/setup/02/","tags":"","title":"Installation for Mac"},{"body":"Installation for Linux Please follow the instructions for your appropriate distribution to install Docker. The recommended way of installing is using the repository, except if you already know you‚Äôre going to remove the package again soon.\nUbuntu Fedora Debian CentOS Unrelated to what distribution you use, also have a look at the Post-installation steps for Linux . Please note however that these are optional steps and some are quite advanced, so going with the default might be the most appropriate way to go.\nProxy configuration for Linux If your organization has a proxy in place you have to set the proxy environment variables in order to be able to do docker pull or docker push.\nexport http_proxy=\"http://\u003cusername\u003e:\u003cpassword\u003e@\u003cproxy\u003e:\u003cport\u003e\" export https_proxy=\"http://\u003cusername\u003e:\u003cpassword\u003e@\u003cproxy\u003e:\u003cport\u003e\" Note If you have special characters in your password, you have to encode them according to Percent-encoding reserved characters . Next steps When you‚Äôre ready to go, head on over to the labs and begin with the training!\n","categories":"","description":"","excerpt":"Installation for Linux Please follow the instructions for your ‚Ä¶","ref":"/setup/03/","tags":"","title":"Installation for Linux"},{"body":"Often you‚Äôre going to use some kind of libraries, tools or dependencies during the build phase of your application that are not necessary during the runtime of the container. To improve security and efficiency we only include whats absolutely necessary in the image. So we often remove these dependencies in the build phase after the application itself has been built.\nIn this lab you‚Äôre going to learn how to use multistage builds and what they are good for.\nPurpose If the application is not available as a prebuilt artifact, in many cases, the application itself gets built directly during the docker build process docker build -t ...\nJava Spring Boot Gradle build Example The complete example can be found at https://github.com/appuio/example-spring-boot-helloworld .\nFROM registry.access.redhat.com/ubi9/openjdk-17 LABEL org.opencontainers.image.authors=\"midcicd@puzzle.ch\" \\ io.k8s.description=\"APPUiO Example Spring Boot App\" \\ io.k8s.display-name=\"APPUiO Spring Boot App\" \\ io.openshift.expose-services=\"8080:http\" \\ io.openshift.tags=\"springboot\" EXPOSE 8080 9000 RUN mkdir -p /tmp/src/ ADD . /tmp/src/ RUN cd /tmp/src \u0026\u0026 sh gradlew build --no-daemon RUN ln -s /tmp/src/build/libs/springboots2idemo*.jar /deployments/springboots2idemo.jar During the docker build the actual application source code is added to the context and built using the gradlew build command. Gradle in this case is only used during the build phase, since it produces a jar that is then executed with java -jar ... at execution time.\nBuild phase dependencies:\nJava Gradle Runtime phase dependencies:\nJava Multi-stage builds With multistage builds you now have the possibility to actually split these two phases, so that you can pass the built artifact from phase one into the runtime phase, without the need of installing build time dependencies in the resulting docker image. Which means that the image will be smaller and consist of less unneeded dependencies.\nRead more about Docker multi-stage builds at https://docs.docker.com/develop/develop-images/multistage-build/ Create a multi-stage build Turn the docker build from the first example (Java Spring boot https://github.com/appuio/example-spring-boot-helloworld ) into a docker multistage build. As a second image you can use registry.access.redhat.com/ubi9/openjdk-17-runtime. Try to find the solution before looking at it.\nPlease create two seperate images to see the actual size difference as well.\nShow me the solution We start by cloning the repository and building the orginal image:\ncd /home/project git clone https://github.com/appuio/example-spring-boot-helloworld.git cd example-spring-boot-helloworld docker build -t example-spring-boot-helloworld:v0.1 . Now let us build the next version using an optimized Dockerfile, change the content of Dockerfile to the text below:\nFROM registry.access.redhat.com/ubi9/openjdk-17 AS build LABEL org.opencontainers.image.authors=\"noreply@acend.ch\" \\ io.k8s.description=\"acend example spring boot app\" \\ io.k8s.display-name=\"acend spring boot app\" \\ io.openshift.expose-services=\"8080:http\" \\ io.openshift.tags=\"springboot\" RUN mkdir -p /tmp/src/ ADD . /tmp/src/ RUN cd /tmp/src \u0026\u0026 sh gradlew build --no-daemon FROM registry.access.redhat.com/ubi9/openjdk-17-runtime EXPOSE 8080 9000 COPY --from=build /tmp/src/build/libs/springboots2idemo*.jar /deployments/springboots2idemo.jar Now build a new version of the image and compare the size:\ndocker build -t example-spring-boot-helloworld:v0.2 . docker images ","categories":"","description":"","excerpt":"Often you‚Äôre going to use some kind of libraries, tools or ‚Ä¶","ref":"/docs/container-basics/01-basics/01/_dockerfile_ms/","tags":"","title":"MultiStage Build"},{"body":"Try Docker without installation The page https://training.play-with-docker.com offers additional tutorials which also come with an interactive shell. The disadvantage is that you have to create an account, but if you don‚Äôt want to install Docker locally, this is a great way to do the exercises in this training using a browser-based Docker shell.\nTo do this lab with Play with Docker:\nGo to https://labs.play-with-docker.com Click on Login Enter your Docker login or register first Click ADD NEW INSTANCE and you are ready to do this training Next steps When you‚Äôre ready to go, head on over to the labs and begin with the training!\n","categories":"","description":"","excerpt":"Try Docker without installation The page ‚Ä¶","ref":"/setup/04/","tags":"","title":"Try Docker without installation"},{"body":"A closer look at the docker command and the runtime We‚Äôve learned that the term ‚ÄúDocker‚Äù is used somewhat imprecisely. It‚Äôs employed to refer to various components such as the CLI (Command Line Interface), the Docker Engine, the OCI image format, and the Container runtime. Let‚Äôs take a closer look at what‚Äôs happening when we use the command\ndocker run --rm -d --name sleep-container alpine sleep 900 We will come to the meaning of -rm and the other arguments later on. For now we need only to know that we started a container which sleeps for 900 seconds on our host. First let us get the process id of the sleep process we just started:\ndocker inspect --format '{{.State.Pid}}' sleep-container Let us see the process running. In the webshell we have the docker backend running in another container, let us first change into that:\nkubectl exec -it deployment/\u003cnamespace\u003e-webshell -c dind -- sh Don‚Äôt worry the command will make sense after the Kubernetes Security training.\nLet us see the process running on the host now, we don‚Äôt have the necessary software installed in our lab so we install it now as well:\nPID=$(pgrep sleep) apk add procps ps -u root -U root --forest -f | grep -B1 $PID we see something like this\nroot 50221 1 0 17:00 ? 00:00:00 /usr/bin/containerd-shim-runc-v2 -namespace moby -id 724930591e3fbf44f9cacb60285c0420464c41f5a6366e2b4443c2b53e6cd251 -address /run/containerd/containerd.sock root 53658 50221 0 17:00 ? 00:00:00 \\_ sleep 900 indeed we see that we don‚Äôt use docker as a container runtime but containerd at a higher level and runc at a lower level. The parent of each of these containerd-shim-runc-v2 processes is PID 1 on the system.\nThe shim becomes the parent process of the containerized application. It is responsible for tasks such as reaping zombie processes, handling container process I/O (standard input, output, error), and ensuring proper container cleanup upon exit. As a result containerd can upgrade and restart without affecting running containers.\nSecondly we see that in the end a container is just a processes running on the host. If nothing else is configured it runs as root! Let us see the different isolation techniques beeing used (again we need to install some software for that):\napk add util-linux lsns -p $PID which shows use the different (and newly created) namespaces beeing used for this container:\nNS TYPE NPROCS PID USER COMMAND 4026531834 time 463 1 root /sbin/init splash # time isolation 4026531837 user 423 1 root /sbin/init splash # uid gid isolation (root inside is not root outside) 4026534002 mnt 1 53658 root sleep 900 4026534003 uts 1 53658 root sleep 900 # hostname isolation 4026534004 ipc 1 53658 root sleep 900 4026534005 pid 1 53658 root sleep 900 4026534006 net 1 53658 root sleep 900 4026534064 cgroup 1 53658 root sleep 900 By comparision a simple sleep command in the current shell would run in the same namespaces as the parent shell giving no isolation.\nDon‚Äôt forget to exit our Docker backend container if you work in the webshell\nexit ","categories":"","description":"","excerpt":"A closer look at the docker command and the runtime We‚Äôve learned that ‚Ä¶","ref":"/docs/container-basics/01-basics/01/_deepdive/","tags":"","title":"Under the hood"},{"body":"Security is important during the entire lifecycle of a container. We will work on various aspects of development and deployment of images as well applied the principle of least privilege to containers and the runtime. It‚Äôs important to configure container isolation, manage user privileges effectively, and follow security best principles (CIA) when orchestrating containers at scale.\n","categories":"","description":"","excerpt":"Security is important during the entire lifecycle of a container. We ‚Ä¶","ref":"/docs/container-basics/02-security/","tags":"","title":"2. Securing Containers"},{"body":"Secure Software Development Lifecycle Docker security covers the entire lifecycle of containers, including their runtime, build process, and orchestration. Key security areas include base images, Dockerfiles, container runtimes, and securing the Docker daemon. Additionally, it‚Äôs important to configure container isolation, manage user privileges effectively, and follow security best practices when orchestrating containers at scale.\nTo ensure we fully understand and manage our workload, it‚Äôs crucial to focus on our Software Development Lifecycle (SDLC). A key part of this is adopting a Secure Software Development Lifecycle (SSDLC) , which integrates security into every stage of development and deployment. One important aspect of a SSDLC is knowing exactly what components are in the software we‚Äôre building and running.\nSBOMs and vulnerabilites A Software Bill of Materials (SBOM) is a detailed list of all the components, libraries, and dependencies used in a software application. It acts like a product inventory for software, allowing developers, security teams, and stakeholders to know exactly what goes into an application. This transparency helps in identifying vulnerabilities, managing licensing risks, and ensuring compliance. With an SBOM, organizations can quickly assess the impact of security vulnerabilities or breaches, as they have a clear view of all the third-party and open-source components in their software stack.\nRecent security issues like the Log4j vulnerability and the SolarWinds breach have underscored the need to know exactly what components are being used in software to mitigate risks quickly. By incorporating SBOMs into CI/CD pipelines, developers can automate the tracking of software dependencies, detect vulnerabilities earlier, and ensure compliance with security standards, reducing the chances of introducing insecure components into production.\nWe have several tools to track the dependencies which our application/images are using an open-source and easy to use one is trivy . Let us try it out with our multi-stage image we built in the previous lab, in case you did not use the tag v0.1 you can add it with docker tag example-spring-boot-helloworld:YOURTAG example-spring-boot-helloworld:v0.1:\ntrivy image --format spdx-json --output result.json example-spring-boot-helloworld:v0.1 Sometimes the trivy API gets overwhelmed with requests and reports an Error, just try again after a minute if that happens. Once done, the scanner will scan the files/image and determine which language is the application written. Once determined, it will download the database pertaining to that specific language and get the list of libraries that are present in that language and check against which are being used in the current context. We can now examine that file and examine all libraries and packes installed in the image\njq . result.json Finally we can check if there are currently know vulnerabilites in these dependencies:\ntrivy sbom result.json We created the SBOM explicitly to show the process, in reality the command can be abbreviated to a simple\ntrivy image example-spring-boot-helloworld:v0.1 As you can see, we obtain the library name, CVE vulnerability number, severity level (HIGH, MEDIUM, LOW), vulnerability status (fixed, not fixed, or will not fix), and if fixed, the version with the fix, along with detailed information about the vulnerability.\nWith this data, we can upgrade libraries with fixes, assess the risk level of unfixed vulnerabilities, and remove unnecessary vulnerable libraries. Additionally, we have the opportunity to explore alternative libraries that are more secure.\nIn our case we might find some vulnerable java libaries which need to be updated in the file build.gradle. If you have some experience with gradle you can try to fix it and build a new image.\nIn SSLDC scanning tools like this are mostly part of a mandatory step in a CI/CD Pipeline before uploading the image to a registry. Generally CVE‚Äôs with a score up to a certain treshold are accepted and the rest is blocked.\n","categories":"","description":"","excerpt":"Secure Software Development Lifecycle Docker security covers the ‚Ä¶","ref":"/docs/container-basics/02-security/02/_ssdlc/","tags":"","title":"SSDLC"},{"body":"This lab focuses on understanding and securing image distribution. We‚Äôll start with a simple docker pull and build up to using Docker Content Trust (DCT).\nLet us start with a common pull\ndocker pull alpine:edge This command will pull the Alpine image tagged as edge. The corresponding image can be found here on Docker Store .\nIf no tag is specified, Docker will pull the image with the latest tag.\n$ docker pull alpine:edge edge: Pulling from library/alpine e587fa4f6e1f: Pull complete Digest: sha256:e5ab6f0941eb01c41595d35856f16215021a941e9893501d632ed4c0ee4e53a6 Status: Downloaded newer image for alpine:edge Now run a new container from the image and ping songlaa.com\ndocker run --rm -it alpine:edge ping songlaa.com Pulling by tag is easy and convenient. However, tags are mutable, and the same tag can refer to different images over time. For example, you can add updates to an image and push the updated image using the same tag as a previous version of the image. This scenario where a single tag points to multiple versions of an image can lead to bugs and vulnerabilities in your production environments.\nThis is why pulling by digest is such a powerful operation. Thanks to the content-addressable storage model used by Docker images, we can target pulls to specific image contents by pulling by digest. In this step you‚Äôll see how to pull by digest.\nPull the Alpine image with the sha256:b7233dafbed64e3738630b69382a8b231726aa1014ccaabc1947c5308a8910a7 digest.\ndocker pull alpine@sha256:b7233dafbed64e3738630b69382a8b231726aa1014ccaabc1947c5308a8910a7 It‚Äôs not easy to find the digest of a particular image tag. This is because it is computed from the hash of the image contents and stored in the image manifest. The image manifest is then stored in the Registry. This is why we needed a docker pull by tag to find digests previously. It would also be desirable to have additional security guarantees such as image freshness.\nEnter Docker Content Trust: a system currently in the Docker Engine that verifies the publisher of images without sacrificing usability. Docker Content Trust implements The Update Framework (TUF), an NSF-funded research project succeeding Thandy of the Tor project. TUF uses a key hierarchy to ensure recoverable key compromise and robust freshness guarantees.\nUnder the hood, Docker Content Trust handles name resolution from IMAGE tags to IMAGE digests by signing its own metadata ‚Äì when Content Trust is enabled, docker will verify the signatures and expiration dates in the metadata before rewriting a pull by tag command to a pull by digest.\nIn this step you will enable Docker Content Trust and pull signed and unsigned images.\nEnable Docker Content Trust by setting the DOCKER_CONTENT_TRUST environment variable.\nexport DOCKER_CONTENT_TRUST=1 All Docker commands remain the same. Docker Content Trust will work silently in the background. Pull the alpine signed image.\ndocker pull alpine That works because the image is trusted.\nNow try to pull an untrusted image\ndocker pull grafgabriel/alpine It will fail with a similiar error (also please never use this image, it is really old)\nError: remote trust data does not exist for docker.io/grafgabriel/alpine: notary.docker.io does not have trust data for docker.io/grafgabriel/alpine If you have Content Trust enabled you can only download trusted images. If you try to push images with content trust enabled Docker will ask you to create a key to sign your images and it will then sign your image before uploading it.\nDocker Content Trust is powered by Notary , an open-source TUF-client and server that can operate over arbitrary trusted collections of data. Notary has its own CLI with robust features such as the ability to rotate keys and remove trust data.\nDisable Content Trust again as we will need to download unsigned images in our lab:\nexport DOCKER_CONTENT_TRUST=0 For more information about Docker Content Trust, see the documentation .\nOfficial images All images in Docker Hub under the library organization (currently viewable at: https://hub.docker.com/explore/ ) are deemed ‚ÄúOfficial Images.‚Äù These images undergo a rigorous, open-source review process to ensure they follow best practices. These best practices include signing, being lean, and having clearly written Dockerfiles. For these reasons, it is strongly recommended that you use official images whenever possible.\nOfficial images can be pulled with just their name and tag. You do not have to precede the image name with library/ or any other repository name.\n","categories":"","description":"","excerpt":"This lab focuses on understanding and securing image distribution. ‚Ä¶","ref":"/docs/container-basics/02-security/02/_trust/","tags":"","title":"Docker Trust"},{"body":"Before exploring different options to minimize container privileges, it‚Äôs important to address a fundamental yet frequently overlooked practice: keeping your software up to date. Regular updates are crucial for protecting against known container escape vulnerabilities, such as Leaky Vessels , which often allow attackers to gain root access to the host. This means both the host system and Docker itself must be consistently updated, including the host kernel and Docker Engine.\nSince containers share the host‚Äôs kernel, a vulnerable kernel exposes all containers to risk. For instance, the Dirty COW kernel privilege escalation exploit , even if run inside a highly isolated container, would still lead to root access on a vulnerable host.\nUser Management in Docker We learnt that if nothing else is configured u user with a container runs as root. Configuring the container to use an unprivileged user is the best way to prevent privilege escalation attacks. This can be accomplished in three different ways.\nRun as different user First during runtime using -u option of docker run command, check the differences\ndocker run alpine id docker run -u guest alpine id Note that the users we are running as must exist in the /etc/passwd of the Docker container. Otherwise, the command will fail as it fails to resolve the username to a user entry in the /etc/passwd file. As an alternative you can run it using an arbitrary uid. In all cases the user must have the necessary rights to execute the binaries or read the files needed in the container. For alpine this works because most binaries are set to read/execute for everyone (755).\nAdd USER to Dockerfile A second way is to set it in the image. Simply add user in Dockerfile and use it, here is an example:\nFROM alpine RUN groupadd -r myuser \u0026\u0026 useradd -r -g myuser myuser # \u003cHERE DO WHAT YOU HAVE TO DO AS A ROOT USER LIKE INSTALLING PACKAGES ETC.\u003e USER myuser Let us apply those two ways to our frontend container as well. By checking the process on your local host we see that we started this container, despite our current knowledge, with root privileges:\ndocker top frontend Which shows an output like similiar to this:\nUID PID PPID C STIME TTY TIME CMD root 19086 19067 1 22:45 ? 00:00:00 /usr/local/bin/python3.9 /usr/local/bin/flask run --host=0.0.0.0 --port=5000 Let us stop and start the container with an user which does not exist on the host:\ndocker stop frontend docker rm frontend docker run -u 1001 -d --name frontend -e username=peter -e password=venkman -e servername=$ip container-lab-frontend:v1.0 docker top frontend Ok, this is fine but even better would be to have it as an default already in the Dockerfile. Please change the Dockerfile of the frontend application to use an new user and build it with a tag of v2.0. Try do do it on you own before checking the solution.\nI'm lost, show me the solution First make sure you are in the right directory:\ncd /home/project/container-lab-fronted Change your Dockerfile to match the content below:\n# Use an official Python runtime as a parent image FROM python:3.12-slim # Set the working directory WORKDIR /app # Install required packages RUN pip install flask mysql-connector-python # Create a non-root user and group RUN groupadd -r appuser \u0026\u0026 useradd -r -g appuser appuser # For the installation we were root, now switch to the non-root user USER appuser # Copy the current directory contents into the container at /app COPY . /app # Set environment variable for Flask ENV FLASK_APP=app.py # Expose port 5000 for the Flask app EXPOSE 5000 # Define the default command to run the app with Flask CMD [\"flask\", \"run\", \"--host=0.0.0.0\", \"--port=5000\"] Now build it using the tag v2.0 make sure you are in the frontend directory:\ndocker build -t container-lab-frontend:v2.0 . Now we stop the currently running container and start our new one:\ndocker stop frontend docker rm frontend export ip=$(docker inspect mariadb-container-with-external-volume -f '{{ range.NetworkSettings.Networks }}{{ .IPAddress }}{{ end }}') docker run --name frontend -d -e username=peter -e password=venkman -e servername=$ip container-lab-frontend:v2.0 docker top frontend Configure the Docker Daemon to user USER namespaces Both ways to change to user are fine. But what, if need to run an image which requires root privileges inside the container?\nThis is where the third option comes into play. It makes use of the Linux USER namespace to re-map the root user within the container to a less-privileged user in the host machine.\nIn this way, the container will be running as root, but that root is mapped to an user that has no privileges on the host. User namespaces are not enabled by default and require to modify the start parametes for the docker deamon.\nMore on that topic in the official documentation .\nOther container runtimes like podman automatically enable user-namespaces, there is a excellent article on that topic here , if you want to read more.\nWhy to avoid running as root We learnt that altough we are root in a container there are restrictions like cgroups, namespaces and capabilities in place so why care?\nThere are multiple ways gain elevated privileges in docker, by having multiple security layers in depth in place we make it harder for an attacker in case of an exploit or a misconfiguration is in place.\n","categories":"","description":"","excerpt":"Before exploring different options to minimize container privileges, ‚Ä¶","ref":"/docs/container-basics/02-security/02/_root/","tags":"","title":"Avoid Root"},{"body":"Understanding container capabilities Capabilities in Linux are fine-grained controls that are part of the POSIX permissions system. These capabilities allow you to limit or extend the privileges of a process. Container capabilities are a set of predefined permissions that control what operations a container can perform on the host system. By default, containers run with a wide set of capabilities, but in many cases, they do not require all of them, so giving them only the permissions they need makes them safer to use.\nSome of the most commonly used capabilities in Docker include:\nCAP_NET_BIND_SERVICE: Allows binding to ports below 1024 (e.g., running a web server on port 80). CAP_SYS_ADMIN: Provides broad system administration privileges (often considered too powerful for most use cases). CAP_CHOWN: Allows changing file ownership. CAP_DAC_OVERRIDE: Allows bypassing file read, write, and execute permission checks. By default, a container has a wide range of these capabilities, but you can restrict or grant specific capabilities using configuration options when starting the container.\nCheck the default capabilites of a container:\ndocker run --rm -it alpine sh -c 'apk add -U libcap; capsh --print' Important for us are the sections Current and Bounding Set, these are the Capabilites a process in our container has or can aquire. You can deny processes from gaining more privileges by adding --security-opt=no-new-privileges to the docker run command.\nFurthermore we have Current Inheritable and Blocked (IAB) Capabilities , this shows the capabilities that the process does NOT have. Each capability here is prefixed with !, indicating that the capability is disabled or not granted.\nConfiguring a Container to Use Only What It Needs In Docker, you can drop unnecessary capabilities or explicitly add only the required ones using the ‚Äìcap-drop and ‚Äìcap-add options in the command line.\nExample: Configuring a Web Server with Minimal Capabilities Consider running an Nginx web server inside a Docker container. By default, the Nginx process needs to bind to port 80, but it doesn‚Äôt need many other elevated privileges.\nLet us optimize our Frontend Application even further. We stop it and then start it with no privileges at all:\ndocker stop frontend docker rm frontend export ip=$(docker inspect mariadb-container-with-external-volume -f '{{ range.NetworkSettings.Networks }}{{ .IPAddress }}{{ end }}') docker run --name frontend -d -e username=peter -e password=venkman -e servername=$ip --cap-drop ALL --security-opt=no-new-privileges container-lab-frontend:v2.0 Let‚Äôs see if it is still running\nfrontendIP=$(docker inspect frontend -f '{{ range.NetworkSettings.Networks }}{{ .IPAddress }}{{ end }}') curl http://$frontendIP:5000 and you should still see the available users in the backend database, we just dropped all CAPs the process in the container doesn‚Äôt need implementing a least privelege strategy.\n","categories":"","description":"","excerpt":"Understanding container capabilities Capabilities in Linux are ‚Ä¶","ref":"/docs/container-basics/02-security/02/_capabilities/","tags":"","title":"Capabilities"},{"body":"So far we configured user and process permissions of the container. Another important step is to check the filesystem permissions and mount options of a container.\nA common method is to run the containers with a read-only filesystem. Let us try to write into a read-only mounted filesystem:\ndocker run --rm --read-only alpine sh -c 'echo \"whatever\" \u003e /tmp/blub' The command fails with an error:\nsh: can't create /tmp/blub: Read-only file system If you still need to write temporary files, we can do that using the --tmpfs, this will create a temporary in-memory filesystem which is gone as soon at the container is stopped.\nTry it using:\ndocker run --rm --read-only --tmpfs /tmp alpine sh -c 'echo \"whatever\" \u003e /tmp/blub' In addition, if the volume is mounted only for reading, mount them as a read-only. It can be done by appending :ro to the -v. Here is an example:\ndocker run -v volume-name:/path/in/container:ro alpine We continue on improving security for our frontend application by adding this options to our docker run command.\ndocker stop frontend docker rm frontend docker run --name frontend -d -e username=peter -e password=venkman -e servername=$ip --cap-drop ALL --security-opt=no-new-privileges --read-only --tmpfs /tmp container-lab-frontend:v2.0 You can check now with curl that our frontend is still running fine:\nfrontendIP=$(docker inspect frontend -f '{{ range.NetworkSettings.Networks }}{{ .IPAddress }}{{ end }}') curl http://$frontendIP:5000 ","categories":"","description":"","excerpt":"So far we configured user and process permissions of the container. ‚Ä¶","ref":"/docs/container-basics/02-security/02/_volumes/","tags":"","title":"Volume security"},{"body":"Introduction to Linux Security Modules Linux Security Modules (LSMs) provide mechanisms for implementing various security policies in Linux. They help in enforcing access controls and securing applications by restricting their capabilities and interactions with the system. The most populare LSMs are:\nSeccomp (Secure Computing Mode):\nSeccomp provides a way to filter system calls that a process can make. By defining a list of allowed or disallowed system calls, it can minimize the attack surface of applications by reducing the risk of exploitation through system call vulnerabilities. This allows you to create even more granular control over the system calls than you would have using capabilities.\nAppArmor (Application Armor):\nAppArmor uses profiles to confine applications and restrict their access to system resources. Each profile defines the permissions for a specific application, including which files it can access, which network operations it can perform, and more. AppArmor is generally easier to manage and configure compared to SELinux. There is a default enabled AppArmor profile for Docker named usually named docker-default. You can find the template for this profile here .\nSELinux (Security-Enhanced Linux):\nSELinux provides a robust mechanism for supporting access control policies. It enforces security policies that dictate how processes interact with each other and with system resources, based on labels assigned to files, processes, and other objects. SELinux offers more granularity and flexibility than AppArmor but can be more complex to configure.\nApplying Seccomp to our frontend container Seccomp can be used to restrict the system calls available to a container, thereby limiting its potential attack surface. Here‚Äôs how you can apply a Seccomp profile to an Nginx container:\nFirst, create a Seccomp profile in JSON format. For example, create a file named frontend-seccomp.json under /home/project with the following content to restrict some potentially risky system calls:\n{ \"defaultAction\": \"SCMP_ACT_ALLOW\", \"syscalls\": [ { \"names\": [ \"accept\", \"bind\", \"connect\", \"getcwd\", \"getdents\", \"getpid\", \"recvfrom\", \"sendto\", \"socket\" ], \"action\": \"SCMP_ACT_ALLOW\" } ] } This profile allows only a subset of system calls necessary for frontend to operate, blocking others. Adding another layer of defense in addition to our dropped capabilites.\nTo apply this profile to our frontend container, you can use the Docker command line with the --security-opt option:\ncd /home/project docker stop frontend docker rm frontend docker run --name frontend -d -e username=peter -e password=venkman -e servername=$ip \\ --cap-drop ALL --security-opt=no-new-privileges \\ --read-only --tmpfs /tmp \\ --security-opt seccomp=frontend-seccomp.json container-lab-frontend:v2.0 You can check if the Seccomp profile is applied by inspecting the container:\ndocker inspect frontend | grep seccomp And again as a final check we test if our service is still available:\nfrontendIP=$(docker inspect frontend -f '{{ range.NetworkSettings.Networks }}{{ .IPAddress }}{{ end }}') curl http://$frontendIP:5000 AppArmor, Seccomp or SELinux can also play an important roles in mitigating unpatched vulnerabilities like Leaky Vessels ","categories":"","description":"","excerpt":"Introduction to Linux Security Modules Linux Security Modules (LSMs) ‚Ä¶","ref":"/docs/container-basics/02-security/02/_lsm/","tags":"","title":"Linux Security Modules"},{"body":"A note on privileged containers The ‚Äìprivileged option in Docker is a special flag that gives the container full access to the host system. It‚Äôs much more powerful than simply assigning specific capabilities because it bypasses most of Docker‚Äôs built-in security restrictions and grants the container elevated permissions, similar to running as root on the host. Often times you will see it in tutorials for running Docker inside Docker or similar things.\nWhen a Docker container is run with the ‚Äìprivileged flag, several key things happen:\nAll Capabilities Granted Full Device Access (Containers usually have limited access to devices on the host system (like /dev, which includes devices like disks, USBs, etc.)) AppArmor and Seccomp Disabled Unrestricted Network Access It‚Äôs recommended to avoid using ‚Äìprivileged unless absolutely necessary and to use capabilities and specific device access options instead for better security and control.\n","categories":"","description":"","excerpt":"A note on privileged containers The ‚Äìprivileged option in Docker is a ‚Ä¶","ref":"/docs/container-basics/02-security/02/_privileged-mode/","tags":"","title":"Privileged Containers"},{"body":"Do the following commands and read the outputs carefully:\nwhoami head -1 /etc/shadow Now do this:\ndocker run -v /etc:/host alpine sh -c 'whoami;head -1 /host/shadow' Why can you suddenly read stuff which you shouldn‚Äôt be allowed to? Are containers not restriced? The answer lies in the architecture of Docker:\nBy default the Docker Deamon runs in root mode without user namespaces enabled. This means we can mount anything from the host into our container and change it there too using the root user inside our container.\nIt gets worse, just read the exerpt below as we don‚Äôt have sudo installed in our webshell:\nuser2@localhost$ whoami user2 user2@localhost$ sudo su Sorry, user user2 may not rund sudo on localhost. user2@localhost$ docker run --rm -it -v /etc/sudoers.d:/host/etc/sudoers.d alpine sh / # echo 'user2 ALL=(ALL) NOPASSWD:ALL' \u003e /host/etc/sudoers.d/user2 / # exit user2@localhost$ sudo su root@localhost$ whoami root To ensure that a user running a container doesn‚Äôt gain root access to your host, you need to run the container engine and the containerized process as a non-root user. This provides multiple layers of security between the service (httpd, MySQL, etc.) and the privileged resources in the operating system.\nRunning the container engine as a non-root user, is one layer of defense, while running the process in the container as a different non-root user offers yet another layer of defense.\nHere is an except from the docs : Rootless mode executes the Docker daemon and containers inside a user namespace. This is very similar to userns-remap mode, except that with userns-remap mode, the daemon itself is running with root privileges, whereas in rootless mode, both the daemon and the container are running without root privileges.\nRunning rootless mode in Docker comes with a set of limitations, most notably that not all storage drivers are allowed and AppArmor is not supported.\nAnother solution would be to switch from Docker to Podman .\nWhile Docker relies on a client-server model, Podman employs a daemonless architecture. With Podman‚Äôs approach, users manage containers directly, eliminating the need for a continuous daemon process in the background.\nCompared to Docker is has stronger default security settings, features like rootless containers, user namespaces, and seccomp profiles are enabled by default. On the image below we see a comparisation between Docker and Podman architecture\nRecap We saw how to run containers and how to secure them avoiding root, dropping capabilites, mounting filesystems readonly and using Linux Security Modules such as seccomp. However it is important to say that because of the architecture of docker anyone who can start container has more privileges on the host. It is still important to secure the Host Operating system and maybe to run a deamonless container technology like podname. What we did not touch are things like network security and monitoring. More an that in the Kubernetes Security lab.\n","categories":"","description":"","excerpt":"Do the following commands and read the outputs carefully:\nwhoami head ‚Ä¶","ref":"/docs/container-basics/02-security/02/_runtime_sec/","tags":"","title":"Container Runtime Security"},{"body":"","categories":"","description":"","excerpt":"","ref":"/categories/","tags":"","title":"Categories"},{"body":" Container Security Training Setup Labs Slides ","categories":"","description":"","excerpt":" Container Security Training Setup Labs Slides ","ref":"/","tags":"","title":"Container Security Training"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/","tags":"","title":"Tags"}]