[{"body":"The command line tool First it is time to become familiar with the command line utility. Using Docker consists of passing at least one command. docker --help shows the available options:\ndocker --help Usage: docker COMMAND A self-sufficient runtime for containers Options: --config string Location of client config files (default \"/home/user/.docker\") -D, --debug Enable debug mode --help Print usage -H, --host list Daemon socket(s) to connect to -l, --log-level string Set the logging level (\"debug\"|\"info\"|\"warn\"|\"error\"|\"fatal\") (default \"info\") --tls Use TLS; implied by --tlsverify --tlscacert string Trust certs signed only by this CA (default \"/home/user/.docker/ca.pem\") --tlscert string Path to TLS certificate file (default \"/home/user/.docker/cert.pem\") --tlskey string Path to TLS key file (default \"/home/user/.docker/key.pem\") --tlsverify Use TLS and verify the remote -v, --version Print version information and quit Management Commands: config Manage Docker configs container Manage containers image Manage images network Manage networks node Manage Swarm nodes plugin Manage plugins secret Manage Docker secrets service Manage services stack Manage Docker stacks swarm Manage Swarm system Manage Docker volume Manage volumes Commands: attach Attach local standard input, output, and error streams to a running container build Build an image from a Dockerfile commit Create a new image from a container's changes cp Copy files/folders between a container and the local filesystem create Create a new container diff Inspect changes to files or directories on a container's filesystem events Get real time events from the server exec Run a command in a running container export Export a container's filesystem as a tar archive history Show the history of an image images List images import Import the contents from a tarball to create a filesystem image info Display system-wide information inspect Return low-level information on Docker objects kill Kill one or more running containers load Load an image from a tar archive or STDIN login Log in to a Docker registry logout Log out from a Docker registry logs Fetch the logs of a container pause Pause all processes within one or more containers port List port mappings or a specific mapping for the container ps List containers pull Pull an image or a repository from a registry push Push an image or a repository to a registry rename Rename a container restart Restart one or more containers rm Remove one or more containers rmi Remove one or more images run Run a command in a new container save Save one or more images to a tar archive (streamed to STDOUT by default) search Search the Docker Hub for images start Start one or more stopped containers stats Display a live stream of container(s) resource usage statistics stop Stop one or more running containers tag Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE top Display the running processes of a container unpause Unpause all processes within one or more containers update Update configuration of one or more containers version Show the Docker version information wait Block until one or more containers stop, then print their exit codes Run 'docker COMMAND --help' for more information on a command. To view the switches available to a specific command, type:\ndocker \u003ccommand\u003e --help To view system-wide information about Docker, use:\ndocker info Hello world (with Docker images) Docker containers are run from Docker images. By default, they pull these images from Docker Hub, a Docker registry managed by Docker Inc, the company behind the Docker project. Anybody can build and host their Docker images on Docker Hub, so for many applications and Linux distributions you‚Äôll find Docker images that are hosted on Docker Hub.\nTo check whether you can access and download images from Docker Hub, type:\ndocker run hello-world The output, which should include the following, indicates that Docker appears to be working correctly:\nHello from Docker. This message shows that your installation appears to be working correctly. ... Your first container üòÉ With this command, we just ran our first container on our computers. It ran a simple process that printed a message to standard out, the container itself is not very useful though.\n","categories":"","description":"","excerpt":"The command line tool First it is time to become familiar with the ‚Ä¶","ref":"/docs/container-basics/01-basics/","tags":"","title":"1. Docker Basics"},{"body":"Docker images You can search for images available on Docker Hub by clicking the Explore link or by typing mariadb into the search field: https://hub.docker.com/search/?q=mariadb\u0026type=image You will get a list of results and the first hit will probably be the official image: https://hub.docker.com/_/mariadb This page contains instructions on how to pull the image. Let‚Äôs pull a certain version of mariadb:\ndocker pull mariadb:11.5 Note Care about security! Check the images before you run them. Is it an official image ? Official Images are a good starting point, please read here why.\nWhat is installed in the image?\nRead the Dockerfile that was used to build the image Check the base image Check the vulnerabilitis of this image. Does it affect your application? Check the dependencies of the image. Compare your images Digest to the sha256 value shown on dockerhub. After an image has been downloaded, you may then run a container using the downloaded image with the sub-command run. If an image has not been downloaded when Docker is executed with the sub-command run, the Docker client will first download the image, then run a container using it:\ndocker run hello-world:linux Note Here we use the linux tag of the hello-world image instead of using latest again. To see the images that have been downloaded to your computer type:\ndocker images The output should look similar to the following:\nREPOSITORY TAG IMAGE ID CREATED SIZE mariadb 11.5 58730544b81b 2 weeks ago 397MB hello-world latest 1815c82652c0 2 months ago 1.84kB hello-world linux 1815c82652c0 2 months ago 1.84kB The hello world container you ran in the previous lab is an example of a container that runs and exits, after emitting a test message. Containers, however, can be much more useful than that, and they can be interactive. After all, they are similar to virtual machines, only more resource-friendly.\nAs an example, let‚Äôs run a container using the downloaded image of MariaDB. The combination of the -i and -t switches gives you interactive shell access to the container:\ndocker run -it mariadb:11.5 An error has popped up!\n2022-08-09 08:19:21+00:00 [Note] [Entrypoint]: Entrypoint script for MariaDB Server 1:10.8.3+maria~jammy started. 2022-08-09 08:19:21+00:00 [Note] [Entrypoint]: Switching to dedicated user 'mysql' 2022-08-09 08:19:21+00:00 [Note] [Entrypoint]: Entrypoint script for MariaDB Server 1:10.8.3+maria~jammy started. 2022-08-09 08:19:21+00:00 [ERROR] [Entrypoint]: Database is uninitialized and password option is not specified You need to specify one of MARIADB_ROOT_PASSWORD, MARIADB_ALLOW_EMPTY_ROOT_PASSWORD and MARIADB_RANDOM_ROOT_PASSWORD ü§î Why do I get an error? Is this a bug in the image? Everything is fine, to run this image there is some configuration needed. Read the following excerpt carefully.\nerror: database is uninitialized and password option is not specified You need to specify one of MARIADB_ROOT_PASSWORD, MARIADB_ALLOW_EMPTY_ROOT_PASSWORD and MARIADB_RANDOM_ROOT_PASSWORD We will add the configuration later.\nü§î What's an image? Think of an image like a blueprint of what will be in a container when it runs.\nAn image is a collection of files + some metadata (or in technical terms: those files form the root filesystem of a container) Images are made of layers, conceptually stacked on top of each other Each layer can add, change or remove files Images can share layers to optimize disk usage, transfer times and memory use You build these images using Dockerfiles (in later labs) Images are immutable, you cannot change them after creation ü§î What's the difference between a container and an image? When you run an image, it becomes a container.\nAn image is a read-only filesystem A container is an encapsulated set of processes running in a read-write copy of that filesystem To optimize container boot time, copy-on-write is used instead of regular copy docker run starts a container from a given image ","categories":"","description":"","excerpt":"Docker images You can search for images available on Docker Hub by ‚Ä¶","ref":"/docs/container-basics/01-basics/01/_images/","tags":"","title":"1.1 Images"},{"body":"Docker architecture Docker is a client-server application The Docker daemon (or ‚ÄúEngine‚Äù) Receives and processes incoming Docker API requests The Docker client Talks to the Docker daemon via the Docker API We‚Äôll use mostly the CLI embedded within the Docker binary The Docker Hub Registry Is a collection of public images The Docker daemon talks to it via the registry API The Docker installation will install the Docker daemon and client on your workstation.\nSetup introduction This training depends on an installation of Docker. If you are attending an official training you are given a pre-installed environment, you can skip this step.\nIf not, follow the instructions on the subsequent pages to complete the setup on your platform of choice.\n","categories":"","description":"","excerpt":"Docker architecture Docker is a client-server application The Docker ‚Ä¶","ref":"/setup/","tags":"","title":"Setup"},{"body":"Environment variables So why was there an error in the previous lab? The MariaDB server is not able to run without a proper configuration. Docker can pass variables into the instantiation process via environment variables. Environment variables are passed via the parameter -e, e.g.:\ndocker run -it -e MARIADB_ROOT_PASSWORD=my-secret-pw mariadb Once you run the command you will see an output like this:\nInitializing database PLEASE REMEMBER TO SET A PASSWORD FOR THE MariaDB root USER ! To do so, start the server, then issue the following commands: '/usr/bin/mysqladmin' -u root password 'new-password' '/usr/bin/mysqladmin' -u root -h password 'new-password' Alternatively you can run: '/usr/bin/mysql_secure_installation' which will also give you the option of removing the test databases and anonymous user created by default. This is strongly recommended for production servers. See the MariaDB Knowledgebase at http://mariadb.com/kb or the MySQL manual for more instructions. Please report any problems at http://mariadb.org/jira The latest information about MariaDB is available at http://mariadb.org/. You can find additional information about the MySQL part at: http://dev.mysql.com Consider joining MariaDB's strong and vibrant community: https://mariadb.org/get-involved/ Database initialized MySQL init process in progress... 2020-05-27 6:21:03 0 [Note] mysqld (mysqld 10.3.7-MariaDB-1:10.3.7+maria~jessie) starting as process 101 ... 2020-05-27 6:21:03 0 [Note] InnoDB: Using Linux native AIO 2020-05-27 6:21:03 0 [Note] InnoDB: Mutexes and rw_locks use GCC atomic builtins 2020-05-27 6:21:03 0 [Note] InnoDB: Uses event mutexes 2020-05-27 6:21:03 0 [Note] InnoDB: Compressed tables use zlib 1.2.8 2020-05-27 6:21:03 0 [Note] InnoDB: Number of pools: 1 2020-05-27 6:21:03 0 [Note] InnoDB: Using SSE2 crc32 instructions 2020-05-27 6:21:03 0 [Note] InnoDB: Initializing buffer pool, total size = 256M, instances = 1, chunk size = 128M ... 2020-05-27 6:21:08 0 [Note] mysqld: ready for connections. Version: '10.3.7-MariaDB-1:10.3.7+maria~jessie' socket: '/var/run/mysqld/mysqld.sock' port: 3306 mariadb.org binary distribution If you re-read the command above you will notify that we used the arguments -it (interactive/terminal). And you might have also found out that mariadb does not react to the usual CTRL-c. So how do we exit this terminal? Docker has an escape sequence to detach from a container and leave it running. For this you have to press CTRL-p and then CTRL-q in bash. In the webshell the shortcuts CTRL-p and CTRL-q are not working. Simply close the terminal and open a new one as a workaround.\nThis will leave the container running while you are back in your shell. To verify that the container is running use the following command:\ndocker ps The output should look much like this:\nCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 7cb31f821233 mariadb \"docker-entrypoint...\" 5 minutes ago Up 5 minutes 3306/tcp upbeat_blackwell Access the container To connect to the container again you can use the following command:\ndocker exec -it \u003ccontainer\u003e bash Where \u003ccontainer\u003e can refer to the CONTAINER ID (the first two characters are normally sufficient) or one of the NAMES from the output of docker ps. In the above output this would be 7cb31f821233 or upbeat_blackwell.\nNote The docker exec command needs either the ID or NAME of the container. Additionally, at the end, an executable. In this example, it‚Äôs bash as we want to do something interactively in the container.\nOnce the command is executed you should see this:\nroot@7cb31f821233:/#\nNote Every time you connect yourself to a container you will always be the user that was defined in the Dockerfile. Now that we are connected, let‚Äôs find out if the MariaDB is working‚Ä¶\nmariadb -uroot -pmy-secret-pw If everything works as expected, you should now see the MariaDB command line:\nWelcome to the MariaDB monitor. Commands end with ; or \\g. Your MariaDB connection id is 8 Server version: 10.3.8-MariaDB-1:10.3.8+maria~jessie mariadb.org binary distribution Copyright (c) 2000, 2020, Oracle, MariaDB Corporation Ab and others. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. MariaDB [(none)]\u003e Type\nexit; to leave the mysql client. Type\nexit one more time to leave the container.\nDetached containers One might think: This whole starting process is a bit cumbersome with CTRL-p and then CTRL-q. Therefore, you can run a Docker container directly with -d (detached) mode, e.g.:\ndocker run -it -e MARIADB_ROOT_PASSWORD=my-secret-pw -d mariadb Instead of the output of the container itself, you will now only get the ID of the started container. If you have a look into the container list, you should see two running containers:\ndocker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 699e82ed8f1f mariadb \"docker-entrypoint...\" 3 minutes ago Up 3 minutes 3306/tcp jolly_bardeen 7cb31f821233 mariadb \"docker-entrypoint...\" 32 minutes ago Up 32 minutes 3306/tcp upbeat_blackwell We don‚Äôt need both of them running. To stop a container use the command:\ndocker stop \u003ccontainer\u003e After that, check the new state with\ndocker ps This should show only one container running:\nCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 699e82ed8f1f mariadb \"docker-entrypoint...\" 9 minutes ago Up 9 minutes 3306/tcp jolly_bardeen We just exited the container ‚Äúgracefully‚Äù, but as an alternative you can also kill a container with the docker kill \u003ccontainer\u003e command. This stops the container immediately by using the KILL signal.\nYou may recognize that the container upbeat_blackwell is not present in the container list anymore. That is because docker ps only shows running containers, but as always you have a parameter that helps:\ndocker ps --all CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 699e82ed8f1f mariadb \"docker-entrypoint...\" 12 minutes ago Up 12 minutes 3306/tcp jolly_bardeen 7cb31f821233 mariadb \"docker-entrypoint...\" 41 minutes ago Exited (0) 2 minutes ago upbeat_blackwell 67d79f95c712 hello-world \"/hello\" About an hour ago Exited (0) About an hour ago upbeat_boyd Now that the upbeat_blackwell container is stopped delete it:\ndocker rm \u003ccontainer\u003e Now the container has disappeared from the list:\ndocker ps --all CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 699e82ed8f1f mariadb \"docker-entrypoint...\" 13 minutes ago Up 13 minutes 3306/tcp jolly_bardeen 67d79f95c712 hello-world \"/hello\" About an hour ago Exited (0) About an hour ago upbeat_boyd It is a good idea to delete unused containers to save disk space and remove the data wich resides in the read/write layer of the container. So please delete the hello-word container too:\ndocker rm \u003ccontainer\u003e Mounting a volume in a container ü§î I have a container with a database server running. What happens to my data when I remove the container? It‚Äôs gone. The docker instance has no persistence layer to store data permanently, let us address that problem in this chapter.\nThe MariaDB container is a good example as to why it‚Äôs good to have an external volume. There are several possibilities on how to work with volumes in Docker, in this case, we‚Äôre going to create a docker volume to store the persistent data of our MariaDB. The volume is managed by Docker itself.\nCreate the docker-managed volume and attach it to a path in the container:\ndocker volume create volume-mariadb docker run --name mariadb-container-with-external-volume -v volume-mariadb:/var/lib/mysql -e MARIADB_ROOT_PASSWORD=my-secret-pw -d mariadb In case you are wondering where your data ends up you can inspect the volume with:\ndocker volume inspect volume-mariadb Okay, now create a new user in the MariaDB container:\ndocker exec -it mariadb-container-with-external-volume mariadb -uroot -pmy-secret-pw Inside the mariadb-client execute some SQL commands to grant user peter permissions to everything:\nuse mysql CREATE USER 'peter'@'%' IDENTIFIED BY 'venkman'; GRANT SELECT ON * . * TO 'peter'@'%'; Once all steps are completed quit the mysql session and exit the container:\nexit ","categories":"","description":"","excerpt":"Environment variables So why was there an error in the previous lab? ‚Ä¶","ref":"/docs/container-basics/01-basics/01/_env-vars/","tags":"","title":"1.2 Environment variables"},{"body":"\nContainer Basics and Security","categories":"","description":"","excerpt":"\nContainer Basics and Security","ref":"/docs/","tags":"","title":"Labs"},{"body":"Frontend Let us create a frontend to showcase port-forwarding and the connection between containers. We will run a simple python webserver which display all the users in our mariadb.\nFirst get the IP of the currently running mariadb container. By default all container are started in the bridge network, where no DNS service is available and we can‚Äôt use container name. As a workaround we use the IP of the container:\nexport ip=$(docker inspect mariadb-container-with-external-volume -f '{{ range.NetworkSettings.Networks }}{{ .IPAddress }}{{ end }}') docker inspect \u003ccontainer\u003e shows you details about a running container in JSON format (run it yourself and take a look at it). We filtered the json to only get the IP address of the container.\nWe could also have filtered the output with grep: docker inspect mariadb-container | grep IPAddress but our solution is more elegant üòä.\nNext we start the frontend container, lucky for us there is an image available online. If interested you can check the source-code here :\ndocker run -d --name frontend -e username=peter -e password=venkman -e servername=$ip grafgabriel/container-lab-frontend Now how do we access it? Try to connect to the server using the container-assigned docker IP address:\ndocker inspect frontend -f '{{ range.NetworkSettings.Networks }}{{ .IPAddress }}{{ end }}' Which will show only the IP of the container as output:\n172.17.0.4:5000 As we don‚Äôt have a browser in the webshell use curl http://172.17.0.4:5000 to open the page in your terminal, on your local installation you can simply open http://172.17.0.4:5000 using your browser.\n","categories":"","description":"","excerpt":"Frontend Let us create a frontend to showcase port-forwarding and the ‚Ä¶","ref":"/docs/container-basics/01-basics/01/_frontend/","tags":"","title":"1.3 Frontend"},{"body":"Installation for Windows Please follow the instructions on Docker‚Äôs official documentation to install Docker CE for Windows.\nWhen asked to use Windows container, choose NOT to.\nNote You don‚Äôt have to register for a Docker Cloud account. Shell recommendation for Windows We highly recommend to use the Bash emulation Git Bash from Git for Windows to do the exercises in this training.\nProxy configuration for Windows If your organization has a proxy in place you have to set the proxy environment variables in order to be able to do docker pull or docker push.\nGit Bash:\nexport HTTP_PROXY=\"http://\u003cusername\u003e:\u003cpassword\u003e@\u003cproxy\u003e:\u003cport\u003e\" export HTTPS_PROXY=\"http://\u003cusername\u003e:\u003cpassword\u003e@\u003cproxy\u003e:\u003cport\u003e\" Note If you have special characters in your password, you have to encode them according to Percent-encoding reserved characters . See also setting the proxy environment variables on Windows for alternative instructions on setting proxy environment variables.\nNext steps When you‚Äôre ready to go, head on over to the labs and begin with the training!\n","categories":"","description":"","excerpt":"Installation for Windows Please follow the instructions on Docker‚Äôs ‚Ä¶","ref":"/setup/01/","tags":"","title":"Installation for Windows"},{"body":" Kubernetes Security Basics Read more\nLab PDF Read more\n","categories":"","description":"","excerpt":" Kubernetes Security Basics Read more\nLab PDF Read more\n","ref":"/slides/","tags":"","title":"Slides"},{"body":"Dockerfile Docker can build container images by reading the instructions on how to build the image from a so-called Dockerfile or more generally, Containerfile. The basic docs on how Dockerfiles work can be found at https://docs.docker.com/engine/reference/builder/ .\nWrite your first Dockerfile Let us have a general look at how to build a container image. For that, create a new directory with an empty Dockerfile in there.\nmkdir myfirstimage cd myfirstimage Create a new File with the name Dockerfile and add the following content to that Dockerfile using your editor of choice:\nFROM ubuntu RUN apt-get update \u0026\u0026 \\ apt-get install -y figlet \u0026\u0026 \\ apt-get clean FROM indicates the base image for our build Each RUN line will be executed by Docker during the build Our RUN commands must be non-interactive (no input can be provided to Docker during the build) Check https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/ for further best practices on how to write Dockerfiles. Build the image Just run:\ndocker build -t myfirstimage . -t indicates the tag to apply to the image . indicates the location of the build context (which we will talk more about later, but is basically the directory where our Dockerfile is located) Please note that the tag can be omitted in most Docker commands and instructions. In that case, the tag defaults to latest. Besides being the default tag there‚Äôs nothing special about latest. Despite its name, it does not necessarily identify the latest version of an image.\nDepending on the build system it can point to the last image pushed, to the last image built from some branch, or to some old image. It can even not exist at all.\nBecause of this, you must never use the latest tag in production, always use a specific image version.\nAlso see: https://medium.com/@mccode/the-misunderstood-docker-tag-latest-af3babfd6375 What happens when we build the image The output of the Docker build looks like this:\nSending build context to Docker daemon 2.048kB Step 1/2 : FROM ubuntu ---\u003e ea4c82dcd15a Step 2/2 : RUN apt-get update \u0026\u0026 apt-get install -y figlet \u0026\u0026 apt-get clean ---\u003e b3c08112fd1c Successfully built b3c08112fd1c Successfully tagged myfirstimage:latest Sending the build context to Docker Sending build context to Docker daemon 84.48 kB ... The build context is the . directory given to docker build It is sent (as an archive) to the Docker daemon by the Docker client This allows you to use a remote machine to build using local files Be careful (or patient) if that directory is big and your connection is slow Inspecting step execution ... Step 1/2 : FROM ubuntu ---\u003e ea4c82dcd15a Step 2/2 : RUN apt-get update \u0026\u0026 apt-get install -y figlet \u0026\u0026 apt-get clean ---\u003e b3c08112fd1c Successfully built b3c08112fd1c Successfully tagged myfirstimage:latest A container (ea4c82dcd15a) is created from the base image The base image will be pulled, if it was not pulled before The RUN command is executed in this container The container is committed into an image (b3c08112fd1c) The build container (ea4c82dcd15a) is removed The output of this step will be the base image for the next one ‚Ä¶ The caching system If you run the same build again, it will be instantaneous. Why?\nAfter each build step, Docker takes a snapshot Before executing a step, Docker checks if it has already built the same sequence Docker uses the exact strings defined in your Dockerfile: RUN apt-get install figlet cowsay is different from RUN apt-get install cowsay figlet RUN apt-get update is not re-executed when the mirrors are updated All steps after a modified step are re-executed since the filesystem it‚Äôs based on may have changed You can force a rebuild with docker build ‚Äìno-cache ‚Ä¶\nIf you only want to trigger a partial rebuild, e.g. run apt-get update to install the latest updates, you can use the following pattern:\nENV REFRESHED_AT 2020-03-13 RUN apt-get update If you update the value of REFRESHED_AT it will invalidate the Docker build cache of that and all the following steps, thus installing the latest updates.\nRun it Now run your image\ndocker run -ti myfirstimage You‚Äôll find yourself inside a Bash shell in the container, execute\nfiglet hello and you will see the following output:\nroot@00f0766080ed:/# figlet hello _ _ _ | |__ ___| | | ___ | '_ \\ / _ \\ | |/ _ \\ | | | | __/ | | (_) | |_| |_|\\___|_|_|\\___/ root@00f0766080ed:/# exit the container by executing:\nexit The CMD instruction in Dockerfile With the CMD instruction in the Dockerfile, we can define the command that is executed when a container is started.\nü§î Can you find out which CMD instruction the ubuntu image has? You did find yourself in a shell, so the instruction must either be /usr/bin/bash or /usr/bin/sh.\nModify the previously created Dockerfile as follows:\nFROM ubuntu RUN apt-get update \u0026\u0026 \\ apt-get install -y figlet \u0026\u0026 \\ apt-get clean CMD [\"figlet\", \"hello\"] Build the image with:\ndocker build -t myfirstimagecmd . And run it:\ndocker run -ti myfirstimagecmd It directly executes the defined command and prints out\n_ _ _ | |__ ___| | | ___ | '_ \\ / _ \\ | |/ _ \\ | | | | __/ | | (_) | |_| |_|\\___|_|_|\\___/ Check out https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact for more information.\nFrontend app image build Now we are familiar with the image building process we have a more detailed look at our frontend image. You can find the source code here .\nWe see that the developer has become quite lazy and has not updated the python to the latest image, he did not even care to create sensible tags. So let us do it ourselfs.\nCheck out the repository\ngit clone https://github.com/songlaa/container-lab-fronted cd container-lab-fronted You should have the necessary knowledge now to update and rebuild the image locally with a sensible tag. Delete the currently running container and start a new one with updated python.\nI'm lost, show me the solution First of all we need to check for the latest python base image. You could do this in dockerhub:\ngrep FROM Dockerfile We see that currently we use version 3.9 of python, a look at https://hub.docker.com/_/python shows us that that the most recent one at the time of writing is 3.12. Replace the from line with this new value\nFROM python:3.12-slim And then we build it using a version tag\ndocker build -t container-lab-frontend:v1.0 . docker images Finally we kill the currently running container and start our new one, hopefully we still have $ip saved in our shell:\ndocker stop frontend docker rm frontend docker run -d --name frontend -e username=peter -e password=venkman -e servername=$ip container-lab-frontend:v1.0 ü§î What did we update by rebuilding the image? We did not only update python to a recent version but also the modules in python! Generally you should build \u0026 deploy very often to avoid configuration drift and keep your software up to date! A common solution to update your dependencies is https://docs.renovatebot.com/ ","categories":"","description":"","excerpt":"Dockerfile Docker can build container images by reading the ‚Ä¶","ref":"/docs/container-basics/01-basics/01/_dockerfile/","tags":"","title":"1.4 Dockerfile"},{"body":"Installation for Mac Please follow the instructions on Docker‚Äôs official documentation to install Docker CE for Mac.\nNote You don‚Äôt have to register for a Docker Cloud account. Proxy configuration for Mac If your organization has a proxy in place you have to set the proxy environment variables in order to be able to do docker pull or docker push.\nexport http_proxy=\"http://\u003cusername\u003e:\u003cpassword\u003e@\u003cproxy\u003e:\u003cport\u003e\" export https_proxy=\"http://\u003cusername\u003e:\u003cpassword\u003e@\u003cproxy\u003e:\u003cport\u003e\" Note If you have special characters in your password, you have to encode them according to Percent-encoding reserved characters . See also setting the proxy environment variables on Mac for alternative instructions on setting proxy environment variables.\nNext steps When you‚Äôre ready to go, head on over to the labs and begin with the training!\n","categories":"","description":"","excerpt":"Installation for Mac Please follow the instructions on Docker‚Äôs ‚Ä¶","ref":"/setup/02/","tags":"","title":"Installation for Mac"},{"body":"Often you‚Äôre going to use some kind of libraries, tools or dependencies during the build phase of your application that are not necessary during the runtime of the container. To improve security and efficiency we only include whats absolutely necessary in the image. So we often remove these dependencies in the build phase after the application itself has been built.\nIn this lab you‚Äôre going to learn how to use multistage builds and what they are good for.\nPurpose If the application is not available as a prebuilt artifact, in many cases, the application itself gets built directly during the docker build process docker build -t ...\nJava Spring Boot Gradle build Example The complete example can be found at https://github.com/appuio/example-spring-boot-helloworld .\nFROM registry.access.redhat.com/ubi9/openjdk-17 LABEL org.opencontainers.image.authors=\"midcicd@puzzle.ch\" \\ io.k8s.description=\"APPUiO Example Spring Boot App\" \\ io.k8s.display-name=\"APPUiO Spring Boot App\" \\ io.openshift.expose-services=\"8080:http\" \\ io.openshift.tags=\"springboot\" EXPOSE 8080 9000 RUN mkdir -p /tmp/src/ ADD . /tmp/src/ RUN cd /tmp/src \u0026\u0026 sh gradlew build --no-daemon RUN ln -s /tmp/src/build/libs/springboots2idemo*.jar /deployments/springboots2idemo.jar During the docker build the actual application source code is added to the context and built using the gradlew build command. Gradle in this case is only used during the build phase, since it produces a jar that is then executed with java -jar ... at execution time.\nBuild phase dependencies:\nJava Gradle Runtime phase dependencies:\nJava Multi-stage builds With multistage builds you now have the possibility to actually split these two phases, so that you can pass the built artifact from phase one into the runtime phase, without the need of installing build time dependencies in the resulting docker image. Which means that the image will be smaller and consist of less unneeded dependencies.\nRead more about Docker multi-stage builds at https://docs.docker.com/develop/develop-images/multistage-build/ Create a multi-stage build Turn the docker build from the first example (Java Spring boot https://github.com/appuio/example-spring-boot-helloworld ) into a docker multistage build. As a second image you can use registry.access.redhat.com/ubi9/openjdk-17-runtime. Try to find the solution before looking at it.\nPlease create two seperate images to see the actual size difference as well.\nShow me the solution We start by cloning the repository and building the orginal image:\ngit clone https://github.com/appuio/example-spring-boot-helloworld.git cd example-spring-boot-helloworld docker build -t example-spring-boot-helloworld:v0.1 . Now let us build the next version using an optimized Dockerfile, change the content of Dockerfile to the text below:\nFROM registry.access.redhat.com/ubi9/openjdk-17 AS build LABEL org.opencontainers.image.authors=\"noreply@acend.ch\" \\ io.k8s.description=\"acend example spring boot app\" \\ io.k8s.display-name=\"acend spring boot app\" \\ io.openshift.expose-services=\"8080:http\" \\ io.openshift.tags=\"springboot\" RUN mkdir -p /tmp/src/ ADD . /tmp/src/ RUN cd /tmp/src \u0026\u0026 sh gradlew build --no-daemon FROM registry.access.redhat.com/ubi9/openjdk-17-runtime EXPOSE 8080 9000 COPY --from=build /tmp/src/build/libs/springboots2idemo*.jar /deployments/springboots2idemo.jar Now build a new version of the image and compare the size:\ndocker build -t example-spring-boot-helloworld:v0.2 . docker images ","categories":"","description":"","excerpt":"Often you‚Äôre going to use some kind of libraries, tools or ‚Ä¶","ref":"/docs/container-basics/01-basics/01/_dockerfile_ms/","tags":"","title":"1.5 MultiStage Build"},{"body":"Installation for Linux Please follow the instructions for your appropriate distribution to install Docker. The recommended way of installing is using the repository, except if you already know you‚Äôre going to remove the package again soon.\nUbuntu Fedora Debian CentOS Unrelated to what distribution you use, also have a look at the Post-installation steps for Linux . Please note however that these are optional steps and some are quite advanced, so going with the default might be the most appropriate way to go.\nProxy configuration for Linux If your organization has a proxy in place you have to set the proxy environment variables in order to be able to do docker pull or docker push.\nexport http_proxy=\"http://\u003cusername\u003e:\u003cpassword\u003e@\u003cproxy\u003e:\u003cport\u003e\" export https_proxy=\"http://\u003cusername\u003e:\u003cpassword\u003e@\u003cproxy\u003e:\u003cport\u003e\" Note If you have special characters in your password, you have to encode them according to Percent-encoding reserved characters . Next steps When you‚Äôre ready to go, head on over to the labs and begin with the training!\n","categories":"","description":"","excerpt":"Installation for Linux Please follow the instructions for your ‚Ä¶","ref":"/setup/03/","tags":"","title":"Installation for Linux"},{"body":"A closer look at the docker command and the runtime We‚Äôve learned that the term ‚ÄúDocker‚Äù is used somewhat imprecisely. It‚Äôs employed to refer to various components such as the CLI (Command Line Interface), the Docker Engine, the OCI image format, and the Container runtime. Let‚Äôs take a closer look at what‚Äôs happening when we use the command\ndocker run --rm -d --name sleep-container alpine sleep 300 We will come to the meaning of -rm and the other arguments later on. For now we need only to know that we started a container which sleeps for 300 seconds on our host. First let us get the process id of the sleep process we just started:\nPID=`docker inspect --format '{{.State.Pid}}' sleep-container` Let us see the process running:\nps -u root -U root --forest -f | grep -B1 $PID we see something like this\nroot 50221 1 0 17:00 ? 00:00:00 /usr/bin/containerd-shim-runc-v2 -namespace moby -id 724930591e3fbf44f9cacb60285c0420464c41f5a6366e2b4443c2b53e6cd251 -address /run/containerd/containerd.sock root 53658 50221 0 17:00 ? 00:00:00 \\_ sleep 300 indeed we see that we don‚Äôt use docker as a container runtime but containerd at a higher level and runc at a lower level. The parent of each of these containerd-shim-runc-v2 processes is PID 1 on the system.\nThe shim becomes the parent process of the containerized application. It is responsible for tasks such as reaping zombie processes, handling container process I/O (standard input, output, error), and ensuring proper container cleanup upon exit. As a result containerd can upgrade and restart without affecting running containers.\nSecondly we see that in the end a container is just a processes running on the host. If nothing else is configured it runs as root! Let us see the different isolation techniques beeing used:\nsudo lsns -p $PID which shows use the different (and newly created) namespaces beeing used for this container:\nNS TYPE NPROCS PID USER COMMAND 4026531834 time 463 1 root /sbin/init splash # time isolation 4026531837 user 423 1 root /sbin/init splash # uid gid isolation (root inside is not root outside) 4026534002 mnt 1 53658 root sleep 900 4026534003 uts 1 53658 root sleep 900 # hostname isolation 4026534004 ipc 1 53658 root sleep 900 4026534005 pid 1 53658 root sleep 900 4026534006 net 1 53658 root sleep 900 4026534064 cgroup 1 53658 root sleep 900 By comparision a simple sleep command in the current shell would run in the same namespaces as the parent shell giving no isolation.\n","categories":"","description":"","excerpt":"A closer look at the docker command and the runtime We‚Äôve learned that ‚Ä¶","ref":"/docs/container-basics/01-basics/01/_deepdive/","tags":"","title":"1.6 Under the hood"},{"body":"Try Docker without installation The page https://training.play-with-docker.com offers additional tutorials which also come with an interactive shell. The disadvantage is that you have to create an account, but if you don‚Äôt want to install Docker locally, this is a great way to do the exercises in this training using a browser-based Docker shell.\nTo do this lab with Play with Docker:\nGo to https://labs.play-with-docker.com Click on Login Enter your Docker login or register first Click ADD NEW INSTANCE and you are ready to do this training Next steps When you‚Äôre ready to go, head on over to the labs and begin with the training!\n","categories":"","description":"","excerpt":"Try Docker without installation The page ‚Ä¶","ref":"/setup/04/","tags":"","title":"Try Docker without installation"},{"body":"Security is important during the entire lifecycle of a container. We will work on various aspects of development and deployment of images as well applied the principle of least privilege to containers and the runtime. It‚Äôs important to configure container isolation, manage user privileges effectively, and follow security best principles (CIA) when orchestrating containers at scale.\n","categories":"","description":"","excerpt":"Security is important during the entire lifecycle of a container. We ‚Ä¶","ref":"/docs/container-basics/02-security/","tags":"","title":"2. Securing Containers"},{"body":"Secure Software Development Lifecycle Docker security covers the entire lifecycle of containers, including their runtime, build process, and orchestration. Key security areas include base images, Dockerfiles, container runtimes, and securing the Docker daemon. Additionally, it‚Äôs important to configure container isolation, manage user privileges effectively, and follow security best practices when orchestrating containers at scale.\nTo ensure we fully understand and manage our workload, it‚Äôs crucial to focus on our Software Development Lifecycle (SDLC). A key part of this is adopting a Secure Software Development Lifecycle (SSDLC) , which integrates security into every stage of development and deployment. One important aspect of a SSDLC is knowing exactly what components are in the software we‚Äôre building and running.\nSBOMs and vulnerabilites A Software Bill of Materials (SBOM) is a detailed list of all the components, libraries, and dependencies used in a software application. It acts like a product inventory for software, allowing developers, security teams, and stakeholders to know exactly what goes into an application. This transparency helps in identifying vulnerabilities, managing licensing risks, and ensuring compliance. With an SBOM, organizations can quickly assess the impact of security vulnerabilities or breaches, as they have a clear view of all the third-party and open-source components in their software stack.\nRecent security issues like the Log4j vulnerability and the SolarWinds breach have underscored the need to know exactly what components are being used in software to mitigate risks quickly. By incorporating SBOMs into CI/CD pipelines, developers can automate the tracking of software dependencies, detect vulnerabilities earlier, and ensure compliance with security standards, reducing the chances of introducing insecure components into production.\nWe have several tools to track the dependencies which our application/images are using an open-source and easy to use one is trivy . Let us try it out with our image we built in the previous lab:\ntrivy image --format spdx-json --output result.json example-spring-boot-helloworld:v0.1 Once done, the scanner will scan the files/image and determine which language is the application written. Once determined, it will download the database pertaining to that specific language and get the list of libraries that are present in that language and check against which are being used in the current context. We can now examine that file and examine all libraries and packes installed in the image\njq . result.json Finally we can check if there are currently know vulnerabilites in these dependencies:\ntrivy sbom result.json We created the SBOM explicitly to show the process, in reality the command can be abbreviated to a simple\ntrivy image example-spring-boot-helloworld:v0.1 As you can see, we obtain the library name, CVE vulnerability number, severity level (HIGH, MEDIUM, LOW), vulnerability status (fixed, not fixed, or will not fix), and if fixed, the version with the fix, along with detailed information about the vulnerability.\nWith this data, we can upgrade libraries with fixes, assess the risk level of unfixed vulnerabilities, and remove unnecessary vulnerable libraries. Additionally, we have the opportunity to explore alternative libraries that are more secure.\nIn our case we might find some vulerable java libaries which need to be updated in the file build.gradle. If you have some experience with gradle you can try to fix it and build a new image.\nIn SSLDC scanning tools like this are mostly part of a mandatory step in a CI/CD Pipeline before uploading the image to a registry. Generally CVE‚Äôs with a score up to a certain treshold are accepted and the rest is blocked.\n","categories":"","description":"","excerpt":"Secure Software Development Lifecycle Docker security covers the ‚Ä¶","ref":"/docs/container-basics/02-security/02/_ssdlc/","tags":"","title":"2.1 SSDLC"},{"body":"Table of Contents Introduction Prerequisites Namespaces PID Namespace Network Namespace Mount Namespace Seccomp AppArmor SELinux Cgroups Additional Security Practices Conclusion Introduction In this lab, you will learn about various security mechanisms available in Docker and containers, including namespaces, seccomp, AppArmor, SELinux, and cgroups. You will also learn how containers communicate with the Linux kernel and how to secure this communication.\nPrerequisites A system with Docker installed (preferably a Linux system) Basic knowledge of Docker and Linux commands Namespaces Namespaces are one of the fundamental building blocks of container isolation. They provide isolated instances of global system resources, ensuring processes inside a container do not interfere with processes outside the container or in other containers.\nPID Namespace Theoretical Introduction: PID namespaces isolate the process ID number space, meaning that processes in different PID namespaces can have the same PID. This is essential for containers, as it allows each container to have its own init process (PID 1).\nFamous Exploits: There have been vulnerabilities related to improper handling of PID namespaces that could potentially lead to privilege escalation, such as CVE-2013-1763.\nExercise:\n# Run a container in detached mode docker run -d --name test-container nginx # Enter the container's namespace docker exec -it test-container bash # Inside the container, check the process tree ps aux # From another terminal, check the process tree on the host ps aux | grep test-container Network Namespace Theoretical Introduction: Network namespaces provide isolated network stacks, including interfaces, IP addresses, routing tables, and firewall rules. This allows each container to have its own network interfaces and IP addresses.\nFamous Exploits: Exploits can occur if containers are allowed to access the host‚Äôs network namespace improperly. For example, CVE-2020-14386 was a Linux kernel vulnerability that could allow container escape through the network namespace.\nExercise:\n# Check network interfaces on the host ip a # Enter the container's network namespace docker exec -it test-container bash # Inside the container, check network interfaces ip a Mount Namespace Theoretical Introduction: Mount namespaces isolate the set of filesystem mount points seen by processes. Changes to mounts in one namespace are not visible to other namespaces, which helps in providing file system isolation.\nFamous Exploits: Improper mount namespace configurations can lead to vulnerabilities like CVE-2014-5206, where an attacker could escape the container by exploiting mounts.\nExercise:\n# Inside the container, create a new file docker exec -it test-container touch /tmp/container-file # Check if the file is present on the host ls /var/lib/docker/containers/\u003ccontainer-id\u003e/mnt/tmp/ # It won't be there because the mount namespace is isolated Seccomp Theoretical Introduction: Seccomp (secure computing mode) is a security feature in the Linux kernel that restricts the system calls a process can make. This helps in limiting the attack surface by disallowing unnecessary or dangerous system calls.\nFamous Exploits: Seccomp has mitigated several kernel vulnerabilities, such as CVE-2014-0038, where improper system call handling could lead to privilege escalation.\nExercise:\n# Run a container with a custom seccomp profile cat \u003c\u003cEOF \u003e my-seccomp-profile.json { \"defaultAction\": \"SCMP_ACT_ERRNO\", \"syscalls\": [ { \"names\": [\"clone\", \"fork\", \"vfork\"], \"action\": \"SCMP_ACT_ALLOW\" } ] } EOF docker run --security-opt seccomp=my-seccomp-profile.json nginx AppArmor Theoretical Introduction: AppArmor (Application Armor) is a Linux security module that provides mandatory access control. It confines programs to a limited set of resources based on a specified profile.\nFamous Exploits: AppArmor has helped mitigate vulnerabilities like CVE-2016-9962, where a misconfigured profile could allow an attacker to escape the Docker container.\nExercise:\n# Check the current AppArmor profiles sudo aa-status # Run a container with a custom AppArmor profile docker run --security-opt \"apparmor=your_profile\" nginx SELinux Theoretical Introduction: SELinux (Security-Enhanced Linux) is another Linux security module providing mandatory access control. It uses security policies to define how processes and users can access resources.\nFamous Exploits: SELinux has been crucial in preventing exploits such as CVE-2017-5123, which could allow a process to gain unauthorized access to system resources.\nExercise:\n# Check the SELinux status sestatus # Run a container with a specific SELinux label docker run --security-opt label:type:your_type nginx Cgroups Theoretical Introduction: Cgroups (control groups) limit, account for, and isolate the resource usage of process groups. This includes CPU, memory, disk I/O, and network bandwidth.\nFamous Exploits: Misconfigurations in cgroups can lead to denial of service attacks, such as CVE-2014-3519, where an attacker could cause excessive resource consumption.\nExercise:\n# Run a container with limited CPU and memory docker run -d --name limited-container --cpus=\".5\" --memory=\"256m\" nginx # Check the resource usage docker stats limited-container Additional Security Practices Theoretical Introduction: In addition to the above mechanisms, there are several best practices to follow to enhance container security. These include using minimal base images, keeping images up to date, scanning images for vulnerabilities, and running containers as non-root users.\nExercise:\n# Example of running a container as a non-root user docker run -u 1000:1000 nginx Conclusion In this lab, you explored various aspects of Docker/container security, including namespaces, seccomp, AppArmor, SELinux, and cgroups. By following these practices and utilizing these tools, you can enhance the security of your containerized applications.\n","categories":"","description":"","excerpt":"Table of Contents Introduction Prerequisites Namespaces PID Namespace ‚Ä¶","ref":"/docs/container/container/","tags":"","title":"Docker/Container Security"},{"body":"Before exploring different options to minimize container privileges, it‚Äôs important to address a fundamental yet frequently overlooked practice: keeping your software up to date. Regular updates are crucial for protecting against known container escape vulnerabilities, such as Leaky Vessels , which often allow attackers to gain root access to the host. This means both the host system and Docker itself must be consistently updated, including the host kernel and Docker Engine.\nSince containers share the host‚Äôs kernel, a vulnerable kernel exposes all containers to risk. For instance, the Dirty COW kernel privilege escalation exploit , even if run inside a highly isolated container, would still lead to root access on a vulnerable host.\nUser Management in Docker We learnt that if nothing else is configured u user with a container runs as root. Configuring the container to use an unprivileged user is the best way to prevent privilege escalation attacks. This can be accomplished in three different ways as follows:\nFirst during runtime using -u option of docker run command, check the differences\ndocker run alpine id docker run -u guest alpine id Note that the users we are running as must exist in the /etc/passwd of the Docker container. Otherwise, the command will fail as it fails to resolve the username to a user entry in the /etc/passwd file. As an alternative you can run it using an arbitrary uid. In all cases the user must have the necessary rights to execute the binaries or read the files needed in the container. For alpine this works because most binaries are set to read/execute for everyone (755).\nA second way is to set it in the image. Simply add user in Dockerfile and use it\nFROM alpine RUN groupadd -r myuser \u0026\u0026 useradd -r -g myuser myuser # \u003cHERE DO WHAT YOU HAVE TO DO AS A ROOT USER LIKE INSTALLING PACKAGES ETC.\u003e USER myuser Let us apply those two ways to our frontend container as well. By checking the process on your local host we see that we started this container, despite our current knowledge, with root privileges:\ndocker top frontend Which shows an output like similiar to this:\nUID PID PPID C STIME TTY TIME CMD root 19086 19067 1 22:45 ? 00:00:00 /usr/local/bin/python3.9 /usr/local/bin/flask run --host=0.0.0.0 --port=5000 Let us stop and start the container with an user which does not exist on the host:\ndocker stop frontend docker rm frontend docker run -u 1001 --name frontend -e username=peter -e password=venkman -e servername=$ip container-lab-frontend:v1.0 docker top frontend Ok, this is fine but even better would be to have it as an default already in the Dockerfile. Please change the Dockerfile of the frontend application to use an new user and build it with a tag of v2.0. Try do do it on you own before checking the solution.\nI'm lost, show me the solution Change your Dockerfile to match the content below:\n# Use an official Python runtime as a parent image FROM python:3.12-slim # Set the working directory WORKDIR /app # Install required packages RUN pip install flask mysql-connector-python # Create a non-root user and group RUN groupadd -r appuser \u0026\u0026 useradd -r -g appuser appuser # For the installation we were root, now switch to the non-root user USER appuser # Copy the current directory contents into the container at /app COPY . /app # Set environment variable for Flask ENV FLASK_APP=app.py # Expose port 5000 for the Flask app EXPOSE 5000 # Define the default command to run the app with Flask CMD [\"flask\", \"run\", \"--host=0.0.0.0\", \"--port=5000\"] Now build it using the tag v2.0 make sure you are in the frontend directory:\ndocker build -t container-lab-frontend:v2.0 . Now we stop the currently running container and start our new one, hopefully we still have $ip saved in our shell:\ndocker stop frontend docker rm frontend docker run --name frontend -e username=peter -e password=venkman -e servername=$ip container-lab-frontend:v2.0 docker top frontend Both ways to change to user are fine. But what, if need to run an image which requires root privileges inside the container? This is where the third option comes into play. It makes use of the Linux USER namespace to re-map the root user within the container to a less-privileged user in the host machine.\nIn this way, the container will be running as root, but that root is mapped to an user that has no privileges on the host. User namespaces are not enabled by default and require to modify the start parametes for the docker deamon.\nUser namespaces are not enabled by default for Docker and require to modify the start parametes for the docker deamon. More on that topic in the official documentation .\n","categories":"","description":"","excerpt":"Before exploring different options to minimize container privileges, ‚Ä¶","ref":"/docs/container-basics/02-security/02/_privileges/","tags":"","title":"2.2 Privileges"},{"body":"","categories":"","description":"","excerpt":"","ref":"/categories/","tags":"","title":"Categories"},{"body":" Welcome to the Kubernetes Security Training Setup Labs Slides ","categories":"","description":"","excerpt":" Welcome to the Kubernetes Security Training Setup Labs Slides ","ref":"/","tags":"","title":"Kubernetes Security Training"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/","tags":"","title":"Tags"}]